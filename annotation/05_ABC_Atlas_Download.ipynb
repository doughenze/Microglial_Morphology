{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482e0601-6753-4c3f-9455-b6f2bdb820d3",
   "metadata": {},
   "source": [
    "This code, and the following two notebooks, are largely inspired by the Allen Brain Cell Atlas's\n",
    "MERFISH atlas. The code used was sourced and adapted from this github: https://github.com/ZhuangLab/whole_mouse_brain_MERFISH_atlas_scripts_2023/blob/main/scripts/integrate_MERFISH_with_scRNA-seq/create_integration_workspace.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e41a1-722a-489f-9fd9-76c3cb81d1bb",
   "metadata": {},
   "source": [
    "Downloading the Allen Brain Cell Atlas: 20230521 release https://data.nemoarchive.org/other/grant/aibs_internal/zeng/transcriptome/scell/10x_v3/mouse/processed/counts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25582e4f-b757-4b27-80fd-fe488471e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import igraph\n",
    "import networkx as nx\n",
    "import metis\n",
    "import ALLCools\n",
    "from ALLCools.integration.seurat_class import SeuratIntegration\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59360cf-ac31-42ee-b214-f9eb44613543",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_file = 'AIT17.0.rawcount_logCPM_10Xv3/AIT17.0.rawcount_logCPM_10Xv3.h5ad'\n",
    "annotation_file = 'AIT17.0.cl.df.v6_lock_230504/AIT17.0.cl.df.v6_lock_230504.tsv'\n",
    "\n",
    "annotation_df = pd.read_csv(annotation_file, sep='\\t')\n",
    "annotation_df['cl'] = annotation_df['cl'].astype(str)\n",
    "subclass_map = {t[0] : t[1] for t in annotation_df[['cl', 'subclass_label']].itertuples(index=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba80a1d-9193-48fb-a44a-ee0e5ad6b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(adata_file)\n",
    "adata.obs['subclass_label'] = adata.obs['cl'].map(subclass_map)\n",
    "\n",
    "# Filter out cells without subclass annotations or annotated as low quality\n",
    "mask_not_na = ~adata.obs['subclass_label'].isna()\n",
    "mask_not_lq = adata.obs['subclass_label'] != 'LQ'\n",
    "adata = adata[mask_not_na & mask_not_lq].copy()\n",
    "gc.collect()\n",
    "\n",
    "adata_raw = anndata.AnnData(X=adata.layers['rawcount'], obs=adata.obs, var=adata.var)\n",
    "adata_raw.write_h5ad('AIT17_10Xv3.h5ad', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039226c-80ec-4f01-a258-acf479ae01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace creation\n",
    "def partition_subclasses(adata, n_partitions):\n",
    "    '''Assign integration partitions as the adata.obs['integration_partion'] column.'''\n",
    "    adata.obs['integration_partition'] = 'p0'\n",
    "    \n",
    "    # Get a sparse matrix of that counts edges between subclasses\n",
    "    ones = adata.obsp['distances'].copy()\n",
    "    ones.data = np.ones(len(ones.data))\n",
    "\n",
    "    g_neighobrs = sc._utils.get_igraph_from_adjacency(ones, directed=True)\n",
    "    vc = igraph.VertexClustering(g_neighobrs, membership=adata.obs['subclass_label'].cat.codes.values)\n",
    "    cluster_graph = vc.cluster_graph(combine_edges='sum')\n",
    "    #cluster_mtx = sc._utils.get_sparse_from_igraph(vc.cluster_graph(combine_edges='sum'), weight_attr='weight')\n",
    "    edges = cluster_graph.get_edgelist()\n",
    "    weights = [e['weight'] for e in cluster_graph.es]\n",
    "    num_clusters = len(vc)\n",
    "    row_indices, col_indices = zip(*edges)\n",
    "    cluster_mtx = csr_matrix((weights, (row_indices, col_indices)), shape=(num_clusters, num_clusters))\n",
    "\n",
    "    \n",
    "    # Partition the cluster level graph\n",
    "    G_cluster = nx.from_scipy_sparse_array(cluster_mtx)\n",
    "    for i in adata.obs['subclass_label'].cat.codes.values:\n",
    "        G_cluster.nodes[i]['weight'] = np.sum(adata.obs['subclass_label'] \n",
    "                                              == adata.obs['subclass_label'].cat.categories[i] )\n",
    "    G_cluster.graph['node_weight_attr'] = 'weight'\n",
    "    \n",
    "    (cut, parts) = metis.part_graph(G_cluster, n_partitions, recursive=False,\n",
    "                                   tpwgts=[1 / n_partitions] * n_partitions) \n",
    "    \n",
    "    # Assign the partitions\n",
    "    for i in range(len(parts)):\n",
    "        mask = (adata.obs['subclass_label'] == adata.obs['subclass_label'].cat.categories[i])\n",
    "        adata.obs.loc[mask, 'integration_partition'] = 'p' + str(parts[i])\n",
    "    \n",
    "    adata.obs['integration_partition'] = adata.obs['integration_partition'].astype('category')\n",
    "    \n",
    "def get_cluster_mean_expression_matrix(adata, cluster_column):\n",
    "    '''Get a dataframe of mean gene expression of each cluster.'''\n",
    "    if scipy.sparse.issparse(adata.X):\n",
    "        X = adata.X.toarray()\n",
    "    else:\n",
    "        X = adata.X\n",
    "   \n",
    "    cell_exp_mtx = pd.DataFrame(X, index=adata.obs[cluster_column], columns=adata.var.index)    \n",
    "    return cell_exp_mtx.groupby(by=cluster_column).mean()\n",
    "\n",
    "def calculate_correlation_matrix(adata, cluster_column):\n",
    "    '''Calculate gene expression correlations between clusters.'''\n",
    "    cluster_mean_exp = get_cluster_mean_expression_matrix(adata, cluster_column)\n",
    "    \n",
    "    # Initialzie the correlation matrix\n",
    "    cluster_ids = np.array(cluster_mean_exp.index)\n",
    "    N_clusters = len(cluster_ids)\n",
    "    correlation_mtx = pd.DataFrame(np.ones((N_clusters, N_clusters)), index=cluster_ids, columns=cluster_ids)\n",
    "    \n",
    "    # Fill the correlation matrix\n",
    "    for i in range(N_clusters):\n",
    "        cluster_id1 = cluster_ids[i]\n",
    "        mean_exps1 = np.array(cluster_mean_exp.loc[cluster_id1])\n",
    "        \n",
    "        for j in range(i + 1, N_clusters):\n",
    "            cluster_id2 = cluster_ids[j]\n",
    "            mean_exps2 = np.array(cluster_mean_exp.loc[cluster_id2])\n",
    "            \n",
    "            r, p = scipy.stats.pearsonr(mean_exps1, mean_exps2)\n",
    "\n",
    "            correlation_mtx.loc[cluster_id1, cluster_id2] = r\n",
    "            correlation_mtx.loc[cluster_id2, cluster_id1] = r\n",
    "            \n",
    "    return correlation_mtx\n",
    "\n",
    "def merge_clusters(obs_df, cluster_col, clusters_to_merge):\n",
    "    merged_cluster_id = sorted(clusters_to_merge)[0]\n",
    "    obs_df[cluster_col][obs_df[cluster_col].isin(clusters_to_merge)] = merged_cluster_id\n",
    "    obs_df[cluster_col] = obs_df[cluster_col].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2721f-fc31-4e4d-8163-777d8431b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = 'integration_workspace'\n",
    "input_seq_file = 'AIT17_10Xv3.h5ad'\n",
    "\n",
    "# Make the top level directories\n",
    "os.makedirs(workspace_path, exist_ok=True)\n",
    "partition_path = os.path.join(workspace_path, 'partitions')\n",
    "os.makedirs(partition_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(workspace_path, 'gene_expression_imputation'), exist_ok=True)\n",
    "\n",
    "%%time\n",
    "# Load the sequencing data\n",
    "adata_seq = sc.read_h5ad(input_seq_file)\n",
    "\n",
    "adata_seq.obs['subclass_label'] = adata_seq.obs['subclass_label'].astype('category')\n",
    "adata_seq.obs['cl'] = adata_seq.obs['cl'].astype('category')\n",
    "\n",
    "# Load the merfish data\n",
    "adata_merfish = sc.read_h5ad('FINAL_ANNOTATION.h5ad')\n",
    "\n",
    "# Rename the genes with different synonyms names\n",
    "adata_merfish.var.rename(index={\n",
    "    'AC102910.1': 'Gm30564', \n",
    "    'BC030499': 'Rskr',\n",
    "    'Ctgf': 'Ccn2',\n",
    "    'Fam196b': 'Insyn2b',\n",
    "    'Fam19a1': 'Tafa1',\n",
    "    'Fam19a2': 'Tafa2',\n",
    "    'Fam19a4': 'Tafa4',\n",
    "    'Fam46a': 'Tent5a',\n",
    "    'Fam84b': 'Lratd2',\n",
    "    'Nov': 'Ccn3',\n",
    "    'Wisp1': 'Ccn4',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e3bfd-7160-46a0-a705-6c6f68fa4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the common genes\n",
    "common_genes = np.array(adata_seq.var_names.intersection(adata_merfish.var_names))\n",
    "adata_merfish = adata_merfish[:, adata_merfish.var.index.isin(common_genes)]\n",
    "adata_merfish.write_h5ad(os.path.join(workspace_path, 'adata_merfish.h5ad'), compression='gzip')\n",
    "\n",
    "adata_seq._inplace_subset_var(common_genes)\n",
    "\n",
    "# Remove the cells without cluster or subclass labels\n",
    "adata_seq = adata_seq[~adata_seq.obs['cl'].isna()]\n",
    "adata_seq = adata_seq[~adata_seq.obs['subclass_label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c9b1a-e980-4691-8ca7-50dbc4b6ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the integration partitions using the sequencing data\n",
    "n_partitions = 80\n",
    "\n",
    "sc.pp.normalize_total(adata_seq, target_sum=1000)\n",
    "sc.pp.log1p(adata_seq)\n",
    "sc.pp.scale(adata_seq)\n",
    "\n",
    "n_pcs=100\n",
    "sc.tl.pca(adata_seq, svd_solver='arpack', n_comps=n_pcs)\n",
    "sc.pp.neighbors(adata_seq, use_rep='X_pca', n_neighbors=15, n_pcs=n_pcs)\n",
    "\n",
    "partition_subclasses(adata_seq, n_partitions)\n",
    "\n",
    "#Merge partitions with too few cells\n",
    "partition_corr_df = calculate_correlation_matrix(adata_seq, 'integration_partition')\n",
    "p_names, p_n_cells = np.unique(adata_seq.obs['integration_partition'], return_counts=True)\n",
    "p_smalls = p_names[p_n_cells < 10000]\n",
    "p_larges = p_names[p_n_cells >= 10000]\n",
    "partition_corr_df = partition_corr_df.loc[p_smalls, p_larges]\n",
    "\n",
    "for p1 in p_smalls:\n",
    "\n",
    "    p2 = partition_corr_df.columns[np.argmax(partition_corr_df.loc[p1])]\n",
    "    \n",
    "    print(f'Merge partitions {p1} and {p2}')\n",
    "    merge_clusters(adata_seq.obs, 'integration_partition', [p1, p2])\n",
    "    \n",
    "seq_annotation_df = adata_seq.obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b32ed-05a0-4fc8-b397-0a9d430a263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reload the sequencing data and assign the partitions\n",
    "adata_seq = sc.read_h5ad(input_seq_file)\n",
    "adata_seq.obs['integration_partition'] = seq_annotation_df['integration_partition']\n",
    "\n",
    "adata_seq.obs['subclass_label'] = adata_seq.obs['subclass_label'].astype('category')\n",
    "adata_seq.obs['cl'] = adata_seq.obs['cl'].astype('category')\n",
    "\n",
    "adata_seq = adata_seq[~adata_seq.obs['cl'].isna()]\n",
    "adata_seq = adata_seq[~adata_seq.obs['subclass_label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221802f-bc8d-4a58-a054-fb91caaedc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_annotation_df.to_csv('seq_annotation_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afbf25-e1c5-4464-84b8-9c9b9063ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_annotation_df# Split the sequencing data for the input of the final round of integration.\n",
    "# Because imputation is done at this round, all genes are included.\n",
    "partitions = adata_seq.obs['integration_partition'].cat.categories\n",
    "\n",
    "print('Partition, N_cells, subclasses')\n",
    "for pn in partitions:\n",
    "    adata_subset = adata_seq[adata_seq.obs['integration_partition'] == pn]\n",
    "    p = os.path.join(partition_path, pn.replace('/', '-').replace(' ', '_'))\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    adata_subset.write_h5ad(os.path.join(p, 'adata_seq.h5ad'), compression='gzip')\n",
    "    \n",
    "    print(f'{pn}, {adata_subset.shape[0]}, {list(np.unique(adata_subset.obs[\"subclass_label\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258853c-4997-4ac7-9029-73a86a913928",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_seq, adata_merfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d46cd-3de7-4a65-9998-0e4a2faefb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_seq_cg_list = []\n",
    "for pn in os.listdir(partition_path):\n",
    "    print(pn)\n",
    "    adata_seq = sc.read_h5ad(os.path.join(partition_path, pn, 'adata_seq.h5ad'))\n",
    "    adata_seq = adata_seq[:, adata_seq.var.index.isin(common_genes)].copy()\n",
    "    adata_seq_cg_list.append(adata_seq)\n",
    "    \n",
    "adata_seq_cg = anndata.concat(adata_seq_cg_list)\n",
    "adata_seq_cg.write_h5ad(os.path.join(workspace_path, 'adata_seq_common_genes.h5ad'), compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
