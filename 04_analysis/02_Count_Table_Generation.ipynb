{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b0e2bf-33a1-49d6-b97a-0c37167ae4f8",
   "metadata": {},
   "source": [
    "# This notebook must be run with the Vizgen_2 conda environment within the Vizgen.sif singularity container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c986de6a-1ef1-4711-8b64-5e3ffbba0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "import Mapping\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "from skimage.morphology import disk, opening, closing\n",
    "from scipy.ndimage import binary_fill_holes, label, distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries, watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3fbb59-d0c9-4b98-b97a-fc198e3c0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_filtered_transcripts(experiment_path):\n",
    "    region_types = ['region_0', 'region_1']\n",
    "    for region in region_types:\n",
    "        file_path = f'{experiment_path}baysor/detected_transcripts.csv'\n",
    "        if os.path.exists(file_path):\n",
    "            return pd.read_csv(file_path,index_col=0)\n",
    "    return None\n",
    "\n",
    "def extract_sub_image_with_padding(image, bbox, padding=10):\n",
    "    min_row, min_col, max_row, max_col = bbox\n",
    "    min_row = max(min_row - padding, 0)\n",
    "    min_col = max(min_col - padding, 0)\n",
    "    max_row = min(max_row + padding, image.shape[0])\n",
    "    max_col = min(max_col + padding, image.shape[1])\n",
    "    return image[min_row:max_row, min_col:max_col], (min_row, min_col)\n",
    "\n",
    "def load_images(batchID, x_ax, y_ax, raw_im, raw_dapi,transcripts):\n",
    "    root = '/hpc/projects/group.quake/doug/Shapes_Spatial/'\n",
    "    \n",
    "    transform_file = f'{root}{batchID}/images/micron_to_mosaic_pixel_transform.csv'\n",
    "    transform_df = pd.read_table(transform_file, sep=' ', header=None)\n",
    "    transformation_matrix = transform_df.values\n",
    "    \n",
    "    x_ax = round(x_ax * transformation_matrix[0, 0] + transformation_matrix[0, 2])\n",
    "    y_ax = round(y_ax * transformation_matrix[1, 1] + transformation_matrix[1, 2])\n",
    "    \n",
    "    #print(f'load {batchID}')\n",
    "    #raw_im = Mapping.load_tiff_image(root + batchID + '/binary_image.tif')\n",
    "    #dapi_im = Mapping.load_tiff_image(root + batchID + '/images/mosaic_DAPI_z3.tif')\n",
    "    \n",
    "    box_size = 500\n",
    "    x_start = x_ax - box_size\n",
    "    x_end = x_ax + box_size\n",
    "    y_start = y_ax - box_size\n",
    "    y_end = y_ax + box_size\n",
    "    \n",
    "    # Extract the sub-image, ensuring the indices are within bounds\n",
    "    sub_image = np.zeros((2 * box_size, 2 * box_size), dtype=raw_im.dtype)\n",
    "    sub_dapi = np.zeros((2 * box_size, 2 * box_size), dtype=raw_dapi.dtype)\n",
    "    \n",
    "    raw_x_start = max(x_start, 0)\n",
    "    raw_x_end = min(x_end, raw_im.shape[1])\n",
    "    raw_y_start = max(y_start, 0)\n",
    "    raw_y_end = min(y_end, raw_im.shape[0])\n",
    "    \n",
    "    sub_x_start = max(0, -x_start)\n",
    "    sub_x_end = sub_x_start + (raw_x_end - raw_x_start)\n",
    "    sub_y_start = max(0, -y_start)\n",
    "    sub_y_end = sub_y_start + (raw_y_end - raw_y_start)\n",
    "    \n",
    "    sub_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end] = raw_im[raw_y_start:raw_y_end, raw_x_start:raw_x_end]\n",
    "    sub_dapi[sub_y_start:sub_y_end, sub_x_start:sub_x_end] = raw_dapi[raw_y_start:raw_y_end, raw_x_start:raw_x_end]\n",
    "    \n",
    "    transcripts_sub = transcripts.loc[\n",
    "        (transcripts.mosaic_x < raw_x_end) & (transcripts.mosaic_x > raw_x_start) &\n",
    "        (transcripts.mosaic_y > raw_y_start) & (transcripts.mosaic_y < raw_y_end)\n",
    "    ].copy()  # Explicitly create a copy\n",
    "\n",
    "    # Now assign the new values without triggering the warning\n",
    "    transcripts_sub['translate_x'] = transcripts_sub.mosaic_x - raw_x_start\n",
    "    transcripts_sub['translate_y'] = transcripts_sub.mosaic_y - raw_y_start\n",
    "    return sub_image, sub_dapi, transcripts_sub, (raw_y_start,raw_y_end, raw_x_start, raw_x_end)\n",
    "\n",
    "def segment_image(im,window_size,foreground=True, dapi=False):\n",
    "    if im.dtype == 'uint16':\n",
    "        im = ((im - im.min()) / (im.max() - im.min()) * 255).astype(np.uint8)\n",
    "    subtract = cv2.fastNlMeansDenoising(im)\n",
    "    if foreground:\n",
    "        pre = cv2.adaptiveThreshold((255 - subtract), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, window_size, 2)\n",
    "    else:\n",
    "        pre = cv2.adaptiveThreshold((subtract), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, window_size, 2)\n",
    "    opened = opening(255 - pre, disk(3))\n",
    "    pre = closing(opened, disk(3))\n",
    "    filled_image = binary_fill_holes(pre).astype(np.uint8)\n",
    "        \n",
    "    return filled_image\n",
    "\n",
    "def roi_picker(im, point=(500, 500), dapi=False):\n",
    "    labeled_array, num_features = label(im)\n",
    "    \n",
    "    if dapi:\n",
    "        # Apply distance transform\n",
    "        distance = distance_transform_edt(labeled_array > 0)\n",
    "        \n",
    "        # Generate markers using connected components after thresholding\n",
    "        coords = peak_local_max(distance, footprint=np.ones((9, 9)), labels=(labeled_array > 0))\n",
    "        mask = np.zeros(distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = label(mask)\n",
    "        # Apply watershed\n",
    "        watershed_labels = watershed(-distance, markers, mask=(labeled_array > 0))\n",
    "        \n",
    "        # Update the labeled array with the watershed labels\n",
    "        labeled_array = watershed_labels\n",
    "\n",
    "        # Initialize variables to track the closest region\n",
    "        closest_region_label = None\n",
    "        min_distance = float('inf')\n",
    "        regions = regionprops(labeled_array)\n",
    "\n",
    "        # Find the closest region to the specified point\n",
    "        for region in regions:\n",
    "            if region.area > 500:\n",
    "                # Calculate the distance from the point to the region's centroid\n",
    "                region_centroid = np.array(region.centroid)\n",
    "                distance = np.linalg.norm(region_centroid - np.array(point))\n",
    "\n",
    "                # Update if this region is closer than previous ones\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_region_label = region.label\n",
    "\n",
    "        if closest_region_label is not None:\n",
    "            isolated_component = labeled_array == closest_region_label\n",
    "            label_image = np.zeros_like(labeled_array)\n",
    "            label_image[isolated_component] = 1\n",
    "            return label_image\n",
    "        else:\n",
    "            return labeled_array\n",
    "    else:\n",
    "        # The original functionality to find the largest region near the point\n",
    "        largest_component_label = None\n",
    "        max_area = 0\n",
    "        regions = regionprops(labeled_array)\n",
    "        for region in regions:\n",
    "            if region.area > 500:\n",
    "                boundary_coords = np.column_stack(np.where(labeled_array == region.label))\n",
    "                distances = np.linalg.norm(boundary_coords - np.array(point), axis=1)\n",
    "                min_dist = np.min(distances)\n",
    "\n",
    "                if min_dist < 50:\n",
    "                    if region.area > max_area:\n",
    "                        max_area = region.area\n",
    "                        largest_component_label = region.label\n",
    "\n",
    "        if largest_component_label is not None:\n",
    "            isolated_component = labeled_array == largest_component_label\n",
    "            label_image = np.zeros_like(labeled_array)\n",
    "            label_image[isolated_component] = 1\n",
    "            return label_image\n",
    "        else:\n",
    "            return labeled_array\n",
    "        \n",
    "def count_gene_overlaps(transcripts, dapi, micro, filled_dapi):\n",
    "    \"\"\"\n",
    "    Counts the occurrences of barcodes (rows) for each gene that overlap with dapi_1, \n",
    "    with the binary difference of micro_1 - dapi_1, and with the binary difference of micro_1 - filled_dapi.\n",
    "    \n",
    "    Parameters:\n",
    "        transcripts (pd.DataFrame): A DataFrame containing 'genes', 'translate_x', and 'translate_y' columns.\n",
    "        dapi_1 (np.array): Binary image representing the region of interest (e.g., DAPI stained area).\n",
    "        micro_1 (np.array): Binary image representing a larger or different region of interest.\n",
    "        filled_dapi (np.array): Binary image representing another region of interest.\n",
    "        \n",
    "    Returns:\n",
    "        result (pd.DataFrame): A subset of the input DataFrame 'transcripts' containing only the barcodes that overlap with\n",
    "                               the binary difference between micro_1 and dapi_1 or the binary difference between \n",
    "                               micro_1 and filled_dapi, along with overlap counts per gene.\n",
    "        dapi_only (pd.DataFrame): A subset of the input DataFrame 'transcripts' containing only the barcodes that overlap exclusively with dapi_1.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcripts = transcripts.copy()\n",
    "    # Calculate the differences\n",
    "    binary_diff_dapi = np.logical_and(micro.astype(bool), np.logical_not(dapi.astype(bool)))\n",
    "    binary_diff_filled_dapi = np.logical_and(micro.astype(bool), np.logical_not(filled_dapi.astype(bool)))\n",
    "\n",
    "    # Initialize counts for overlap\n",
    "    #transcripts['overlap_dapi'] = 0\n",
    "    #transcripts['overlap_diff_filled_dapi'] = 0\n",
    "\n",
    "    # Iterate over the transcripts and check for overlap\n",
    "    #for index, row in transcripts.iterrows():\n",
    "     #   x, y = int(row['translate_x']), int(row['translate_y'])\n",
    "     #   if dapi[y, x]:  # Check if the point overlaps with dapi_1\n",
    "     #       transcripts.at[index, 'overlap_dapi'] = 1\n",
    "     #   if binary_diff_filled_dapi[y, x]:  # Check if the point overlaps with the binary difference micro_1 - filled_dapi\n",
    "     #       transcripts.at[index, 'overlap_diff_filled_dapi'] = 1\n",
    "\n",
    "    # Subset the DataFrame to only include rows where there is an overlap in the desired regions\n",
    "    #result = transcripts[\n",
    "     #   (transcripts['overlap_diff_filled_dapi'] > 0) &\n",
    "      #  (transcripts['overlap_dapi'] == 0)\n",
    "    #]\n",
    "\n",
    "    # Group by gene and sum the overlaps\n",
    "\n",
    "    # Subset the DataFrame to only include rows where there is overlap exclusively with dapi_1\n",
    "    #dapi_only = transcripts[\n",
    "     #   (transcripts['overlap_dapi'] > 0) &\n",
    "     #   (transcripts['overlap_diff_filled_dapi'] == 0)\n",
    "    #]\n",
    "    \n",
    "    results = transcripts[\n",
    "        (transcripts['translate_x'].astype(int) >= 0) & (transcripts['translate_x'].astype(int) < binary_diff_filled_dapi.shape[1]) &\n",
    "        (transcripts['translate_y'].astype(int) >= 0) & (transcripts['translate_y'].astype(int) < binary_diff_filled_dapi.shape[0])\n",
    "    ]\n",
    "\n",
    "    results = results[\n",
    "        binary_diff_filled_dapi[results['translate_y'].astype(int), results['translate_x'].astype(int)]\n",
    "    ]\n",
    "    \n",
    "    dapi_only = transcripts[\n",
    "        (transcripts['translate_x'].astype(int) >= 0) & (transcripts['translate_x'].astype(int) < dapi.shape[1]) &\n",
    "        (transcripts['translate_y'].astype(int) >= 0) & (transcripts['translate_y'].astype(int) < dapi.shape[0])\n",
    "    ]\n",
    "\n",
    "    dapi_only = dapi_only[\n",
    "        dapi.astype(bool)[dapi_only['translate_y'].astype(int), dapi_only['translate_x'].astype(int)]\n",
    "    ]\n",
    "    \n",
    "\n",
    "    return results, dapi_only\n",
    "\n",
    "def calculate_areas(dataframe, dapi_labeled_array, non_dapi_labeled_array):\n",
    "    \"\"\"\n",
    "    Calculate the total area of the DAPI (nucleus) and non-DAPI (non-nucleus) regions.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): A DataFrame with one row, which will be used to create the output DataFrame.\n",
    "        dapi_labeled_array (np.array): A labeled array where each unique integer represents a different object in the nucleus (DAPI).\n",
    "        non_dapi_labeled_array (np.array): A labeled array where each unique integer represents a different object in the non-nucleus (Non-DAPI).\n",
    "\n",
    "    Returns:\n",
    "        result_df (pd.DataFrame): A DataFrame with the same index as the input DataFrame, containing two columns:\n",
    "                                  'DAPI Area' and 'Non-DAPI Area'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate total area for DAPI (nucleus)\n",
    "    dapi_total_area = sum(region.area for region in regionprops(dapi_labeled_array))\n",
    "    \n",
    "    # Calculate total area for Non-DAPI (non-nucleus)\n",
    "    non_dapi_total_area = sum(region.area for region in regionprops(non_dapi_labeled_array))\n",
    "    \n",
    "    # Create a new DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'DAPI Area': [dapi_total_area],\n",
    "        'Non-DAPI Area': [non_dapi_total_area]\n",
    "    }, index=dataframe.index)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def generate_counts_matrix(dataframe, var_names):\n",
    "    \"\"\"\n",
    "    Generate a counts matrix where columns are genes and rows contain the number of barcodes \n",
    "    for that gene present in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing barcode information.\n",
    "        var_names (list or pd.Index): List of gene names (matching adata.var_names).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with genes as columns and the number of barcodes for each gene.\n",
    "    \"\"\"\n",
    "    # Filter the dataframe to only include genes in var_names\n",
    "    filtered_df = dataframe[dataframe['gene'].isin(var_names)]\n",
    "    \n",
    "    # Count the number of barcodes for each gene\n",
    "    counts = filtered_df['gene'].value_counts().reindex(var_names, fill_value=0)\n",
    "    \n",
    "    # Convert the counts to a DataFrame\n",
    "    counts_df = counts.to_frame().T\n",
    "    \n",
    "    return counts_df\n",
    "\n",
    "def rename_index(df, adata,blanks):\n",
    "    counts_matrix_result = generate_counts_matrix(df, adata.var_names.tolist()+blanks)\n",
    "    counts_matrix_result.index = adata.obs.index\n",
    "    return counts_matrix_result\n",
    "\n",
    "def generate_transcript_spreadsheet(transcripts, dapi, micro, ad_test):\n",
    "    # Calculate the union of dapi_1 and micro_1\n",
    "    union_mask = np.logical_or(dapi.astype(bool), micro.astype(bool))\n",
    "    \n",
    "    #transcripts['overlap'] = 0\n",
    "    \n",
    "    #for index, row in transcripts.iterrows():\n",
    "     #   x, y = int(row['translate_x']), int(row['translate_y'])\n",
    "     #   if union_mask[y, x]:\n",
    "      #      transcripts.at[index, 'overlap'] = 1\n",
    "            \n",
    "    #filtered_transcripts = transcripts[transcripts.overlap > 0]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter transcripts to include only those within the union of dapi_1 and micro_1\n",
    "    filtered_transcripts = transcripts[\n",
    "        (transcripts['translate_x'].astype(int) >= 0) & (transcripts['translate_x'].astype(int) < union_mask.shape[1]) &\n",
    "        (transcripts['translate_y'].astype(int) >= 0) & (transcripts['translate_y'].astype(int) < union_mask.shape[0])\n",
    "    ]\n",
    "\n",
    "    filtered_transcripts = filtered_transcripts[\n",
    "        union_mask[filtered_transcripts['translate_y'].astype(int), filtered_transcripts['translate_x'].astype(int)]\n",
    "    ]\n",
    "\n",
    "    # Create a new DataFrame for the spreadsheet\n",
    "    spreadsheet_df = pd.DataFrame({\n",
    "        'x': filtered_transcripts['translate_x'].astype(int),\n",
    "        'y': filtered_transcripts['translate_y'].astype(int),\n",
    "        'gene': filtered_transcripts['gene'],\n",
    "        'cell': ad_test.obs.Name.iloc[0]\n",
    "    })\n",
    "    return spreadsheet_df\n",
    "\n",
    "def apply_bbox_to_image(image, bbox):\n",
    "    \"\"\"\n",
    "    Apply a bounding box to a separate image by cropping or highlighting the region.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The image to which the bounding box will be applied (as a NumPy array).\n",
    "    - bbox: The bounding box as a tuple (min_row, min_col, max_row, max_col).\n",
    "    \n",
    "    Returns:\n",
    "    - Cropped or highlighted image.\n",
    "    \"\"\"\n",
    "    min_row, min_col, max_row, max_col = bbox\n",
    "    \n",
    "    # Crop the region from the new image\n",
    "    cropped_image = image[min_row:max_row, min_col:max_col]\n",
    "\n",
    "    # Show the original image with the bounding box    \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e4c724-8807-4ae4-9571-8cc7b692a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3-mo-male-1: 100%|██████████| 311/311 [05:18<00:00,  1.02s/it]\n",
      "Processing 3-mo-male-2: 100%|██████████| 182/182 [03:01<00:00,  1.00it/s]\n",
      "Processing 3-mo-male-3-rev2: 100%|██████████| 450/450 [07:44<00:00,  1.03s/it]\n",
      "Processing 3-mo-female-1-rev2: 100%|██████████| 309/309 [05:30<00:00,  1.07s/it]\n",
      "Processing 3-mo-female-2: 100%|██████████| 269/269 [04:37<00:00,  1.03s/it]\n",
      "Processing 3-mo-female-3: 100%|██████████| 702/702 [12:17<00:00,  1.05s/it]\n",
      "Processing 24-mo-male-1: 100%|██████████| 75/75 [01:14<00:00,  1.01it/s]\n",
      "Processing 24-mo-male-2: 100%|██████████| 593/593 [10:12<00:00,  1.03s/it]\n",
      "Processing 24-mo-male-4-rev2: 100%|██████████| 106/106 [01:50<00:00,  1.05s/it]\n",
      "Processing 24-mo-female-1: 100%|██████████| 281/281 [04:40<00:00,  1.00it/s]\n",
      "Processing 24-mo-female-3: 100%|██████████| 648/648 [11:11<00:00,  1.04s/it]\n",
      "Processing 24-mo-female-5: 100%|██████████| 539/539 [09:24<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "ad_parent = sc.read_h5ad('../03_morph_embedding/Shape_500.h5ad')\n",
    "ad_parent = ad_parent[ad_parent.obs.updated_celltype == 'Microglia']\n",
    "\n",
    "experiment_base_paths = ['/hpc/projects/group.quake/doug/Shapes_Spatial/3-mo-male-1/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/3-mo-male-2/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/3-mo-male-3-rev2/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/3-mo-female-1-rev2/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/3-mo-female-2/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/3-mo-female-3/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/24-mo-male-1/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/24-mo-male-2/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/24-mo-male-4-rev2/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/24-mo-female-1/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/24-mo-female-3/',\n",
    "                         '/hpc/projects/group.quake/doug/Shapes_Spatial/24-mo-female-5/',\n",
    "                        ]\n",
    "for experiment in experiment_base_paths:\n",
    "    batch = experiment.split('/')[-2]\n",
    "    # We also want to load in the geometry file\n",
    "    ad_viz = ad_parent[ad_parent.obs.batchID == batch]\n",
    "    transform_file = f'{experiment}/images/micron_to_mosaic_pixel_transform.csv'\n",
    "    transform_matrix = pd.read_table(transform_file, sep=' ', header=None).iloc[:2]\n",
    "    transcripts = find_filtered_transcripts(experiment)\n",
    "    transcripts['mosaic_x'], transcripts['mosaic_y'] = transcripts.global_x * transform_matrix.iloc[0,0] + transform_matrix.iloc[0,2], transcripts.global_y * transform_matrix.iloc[1,1] + transform_matrix.iloc[1,2]\n",
    "    blank_names = transcripts[transcripts.gene.str.contains('Blank')].gene.unique().tolist()\n",
    "\n",
    "    root = '/hpc/projects/group.quake/doug/Shapes_Spatial/'\n",
    "    raw_im = Mapping.load_tiff_image(root + batch + '/binary_image.tif')\n",
    "    raw_dapi = Mapping.load_tiff_image(root + batch + '/images/mosaic_DAPI_z3.tif')\n",
    "    final_df_non_nuc = pd.DataFrame(columns=ad_viz.var_names.tolist()+blank_names)\n",
    "    final_df_nuc = pd.DataFrame(columns=ad_viz.var_names.tolist()+blank_names)\n",
    "    final_df_tot = pd.DataFrame(columns=ad_viz.var_names.tolist()+blank_names)\n",
    "    total_trans_df = pd.DataFrame(columns=['x','y','gene','cell'])\n",
    "    for i in tqdm(range(len(ad_viz)), desc=f\"Processing {batch}\"):\n",
    "        ad_test = ad_viz[i,:]\n",
    "        small_raw, small_dapi, small_transcripts,box = load_images(batch, ad_test.obs.x.iloc[0], ad_test.obs.y.iloc[0],raw_im, raw_dapi,transcripts)\n",
    "    \n",
    "        filled_raw = segment_image(small_raw, 205, foreground=True)\n",
    "        filled_dapi = segment_image(small_dapi, 255, foreground=True, dapi=True)\n",
    "    \n",
    "        micro_1 = roi_picker(filled_raw)\n",
    "        dapi_1 = roi_picker(filled_dapi,dapi=True)\n",
    "    \n",
    "        counts_non_nuclei, counts_nuclei = count_gene_overlaps(small_transcripts,dapi_1,micro_1,filled_dapi)\n",
    "    \n",
    "        counts_matrix_result_full = rename_index(counts_non_nuclei,ad_test,blank_names)\n",
    "        counts_matrix_result_dapi = rename_index(counts_nuclei,ad_test,blank_names)\n",
    "        #area_results = calculate_areas(ad_test.obs, dapi_1, label(np.logical_and(micro_1.astype(bool), np.logical_not(filled_dapi.astype(bool))).astype(np.uint8))[0])\n",
    "        sub_full_trans = generate_transcript_spreadsheet(small_transcripts, dapi_1, micro_1, ad_test)\n",
    "        counts_matrix_full = rename_index(sub_full_trans,ad_test,blank_names)\n",
    "        \n",
    "        final_df_non_nuc = pd.concat([final_df_non_nuc, counts_matrix_result_full],axis=0)\n",
    "        final_df_nuc = pd.concat([final_df_nuc, counts_matrix_result_dapi],axis=0)\n",
    "        final_df_tot = pd.concat([final_df_tot, counts_matrix_full],axis=0)\n",
    "        total_trans_df = pd.concat([total_trans_df, sub_full_trans],axis=0)\n",
    "    os.makedirs('transcript_out', exist_ok=True)\n",
    "    final_df_non_nuc.to_csv(f'transcript_out/{batch}_non_nuc.csv')\n",
    "    final_df_nuc.to_csv(f'transcript_out/{batch}_nuc.csv')\n",
    "    final_df_tot.to_csv(f'transcript_out/{batch}_nuc_y_non_nuc.csv')\n",
    "    total_trans_df.to_csv(f'transcript_out/{batch}_complete.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
