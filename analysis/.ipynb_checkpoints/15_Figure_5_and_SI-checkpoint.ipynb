{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ae033-b6b9-4f92-81ee-23c934060ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "import Mapping\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "from skimage.morphology import disk, opening, closing\n",
    "from scipy.ndimage import binary_fill_holes, label, distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries, watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from skimage.segmentation import watershed\n",
    "import anndata\n",
    "from adjustText import adjust_text\n",
    "import gseapy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ddb93-5112-4a84-8308-d0835c8b001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_log_normalized(adata):\n",
    "    \"\"\"\n",
    "    Shift log-normalized values to be non-negative.\n",
    "    \n",
    "    Parameters:\n",
    "    adata : AnnData\n",
    "        Annotated data matrix.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData\n",
    "        AnnData object with shifted log-normalized values.\n",
    "    \"\"\"\n",
    "    adata_copy = adata.copy()\n",
    "    min_val = adata_copy.X.min()\n",
    "    if min_val < 0:\n",
    "        adata_copy.X = adata_copy.X - min_val\n",
    "    return adata_copy\n",
    "\n",
    "def differential_expression(adata1, adata2, shift_log_values=False):\n",
    "    \"\"\"\n",
    "    Perform differential expression analysis between two AnnData objects.\n",
    "\n",
    "    Parameters:\n",
    "    adata1 : AnnData\n",
    "        First annotated data matrix.\n",
    "    adata2 : AnnData\n",
    "        Second annotated data matrix.\n",
    "    shift_log_values : bool\n",
    "        Whether to shift log-normalized values to be non-negative.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        DataFrame containing differential expression results.\n",
    "    \"\"\"\n",
    "    # Add a column indicating the origin of each cell\n",
    "    adata1.obs['group'] = 'group1'\n",
    "    adata2.obs['group'] = 'group2'\n",
    "\n",
    "    if shift_log_values:\n",
    "        adata1 = shift_log_normalized(adata1)\n",
    "        adata2 = shift_log_normalized(adata2)\n",
    "\n",
    "    # Concatenate the two AnnData objects\n",
    "    adata_combined = adata1.concatenate(adata2, batch_key='batch', batch_categories=['group1', 'group2'])\n",
    "\n",
    "    # Perform differential expression analysis using Scanpy\n",
    "    sc.tl.rank_genes_groups(adata_combined, groupby='batch', reference='group1', method='wilcoxon',use_raw=False)\n",
    "\n",
    "    # Extract results into a DataFrame\n",
    "    results = adata_combined.uns['rank_genes_groups']\n",
    "    groups = results['names'].dtype.names\n",
    "    pvals = pd.DataFrame({group + '_pvals': results['pvals'][group] for group in groups})\n",
    "    pvals_adj = pd.DataFrame({group + '_pvals_adj': results['pvals_adj'][group] for group in groups})\n",
    "    logfoldchanges = pd.DataFrame({group + '_logfoldchanges': results['logfoldchanges'][group] for group in groups})\n",
    "    names = pd.DataFrame({group + '_names': results['names'][group] for group in groups})\n",
    "\n",
    "    return pd.concat([names, pvals, pvals_adj, logfoldchanges], axis=1)\n",
    "\n",
    "def plot_volcano(\n",
    "    df, \n",
    "    sig_lfc=0.5, \n",
    "    group='group2', \n",
    "    pval_col_suffix='_pvals', \n",
    "    logfc_col_suffix='_logfoldchanges', \n",
    "    name_col_suffix='_names', \n",
    "    title='Volcano Plot', \n",
    "    xlims=None, \n",
    "    savefig=None,\n",
    "    figsize=(10, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a volcano plot for differential expression analysis results.\n",
    "\n",
    "    Parameters:\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing differential expression results.\n",
    "    group : str\n",
    "        Group name for differential expression results.\n",
    "    pval_col_suffix : str\n",
    "        Suffix for the p-value column in the DataFrame.\n",
    "    logfc_col_suffix : str\n",
    "        Suffix for the log fold change column in the DataFrame.\n",
    "    name_col_suffix : str\n",
    "        Suffix for the gene names column in the DataFrame.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    xlims : tuple, optional\n",
    "        Limits for the x-axis.\n",
    "    savefig : str, optional\n",
    "        Path to save the figure.\n",
    "\n",
    "    Returns:\n",
    "    list, list\n",
    "        Two lists containing significant genes with log fold change < 1 and > 1, ordered by log fold change.\n",
    "    \"\"\"\n",
    "    pvals = df[group + pval_col_suffix]\n",
    "    logfoldchanges = df[group + logfc_col_suffix]\n",
    "    gene_names = df[group + name_col_suffix]\n",
    "    \n",
    "    # Define significance thresholds\n",
    "    sig_pval = 0.05\n",
    "    sig_logfc = sig_lfc\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(logfoldchanges, -np.log10(pvals), color='grey', alpha=0.5, label='NS')\n",
    "    \n",
    "    # Highlight significant points\n",
    "    sig_points = (pvals < sig_pval) & (np.abs(logfoldchanges) > sig_logfc)\n",
    "    plt.scatter(logfoldchanges[sig_points], -np.log10(pvals[sig_points]), color='red', alpha=0.50, label='P-value and log2 FC')\n",
    "    plt.scatter(logfoldchanges[(pvals < sig_pval) & ~sig_points], -np.log10(pvals[(pvals < sig_pval) & ~sig_points]), color='blue', alpha=0.50, label='P-value')\n",
    "    plt.scatter(logfoldchanges[~(pvals < sig_pval) & (np.abs(logfoldchanges) > sig_logfc)], -np.log10(pvals[~(pvals < sig_pval) & (np.abs(logfoldchanges) > sig_logfc)]), color='green', alpha=0.50, label='Log2 FC')\n",
    "    \n",
    "    plt.axhline(y=-np.log10(sig_pval), color='black', linestyle='--')\n",
    "    plt.axvline(x=sig_logfc, color='black', linestyle='--')\n",
    "    plt.axvline(x=-sig_logfc, color='black', linestyle='--')\n",
    "    \n",
    "    # Annotate significant genes\n",
    "    texts = []\n",
    "    sig_genes_less_than_1 = []  # List for significant genes with logFC < -1\n",
    "    sig_genes_greater_than_1 = []  # List for significant genes with logFC > 1\n",
    "\n",
    "    for i in range(len(gene_names)):\n",
    "        if sig_points[i]:\n",
    "            if logfoldchanges[i] < -1 * sig_lfc:\n",
    "                sig_genes_less_than_1.append((gene_names[i], logfoldchanges[i]))  # Store the gene and its logFC\n",
    "            elif logfoldchanges[i] > sig_lfc:\n",
    "                sig_genes_greater_than_1.append((gene_names[i], logfoldchanges[i]))  # Store the gene and its logFC\n",
    "\n",
    "            texts.append(plt.text(logfoldchanges[i], -np.log10(pvals[i]), gene_names[i], fontsize=8))\n",
    "    \n",
    "    adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black'))\n",
    "    \n",
    "    plt.xlabel('Log2 fold change')\n",
    "    plt.ylabel('-Log10 P-value')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    if xlims is not None:\n",
    "        plt.xlim(xlims)\n",
    "        \n",
    "    if savefig is not None:\n",
    "        plt.savefig(savefig, format='pdf')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # Sort the lists by the absolute value of log fold change\n",
    "    sig_genes_less_than_1 = sorted(sig_genes_less_than_1, key=lambda x: abs(x[1]), reverse=True)\n",
    "    sig_genes_greater_than_1 = sorted(sig_genes_greater_than_1, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Extract only the gene names after sorting\n",
    "    sig_genes_less_than_1 = [gene for gene, logfc in sig_genes_less_than_1]\n",
    "    sig_genes_greater_than_1 = [gene for gene, logfc in sig_genes_greater_than_1]\n",
    "    \n",
    "    return sig_genes_less_than_1, sig_genes_greater_than_1\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "def calculate_spearman_corr(adata, gene_columns, morpho_columns):\n",
    "    \"\"\"\n",
    "    Calculate Spearman correlation between gene expression and morphological features.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata: AnnData object containing gene expression and morphological features.\n",
    "    - gene_columns: List of gene names in adata.var_names.\n",
    "    - morpho_columns: List of morphological feature names in adata.obs.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame with Spearman correlation coefficients between genes and morphological features.\n",
    "    \"\"\"\n",
    "    # Extract gene expression data (assume it's stored in adata.X or adata.var)\n",
    "    gene_expr_df = pd.DataFrame(adata[:, gene_columns].X, columns=gene_columns, index=adata.obs_names)\n",
    "    \n",
    "    # Extract morphological features from adata.obs\n",
    "    morpho_df = adata.obs[morpho_columns]\n",
    "    \n",
    "    # Initialize a DataFrame to store the correlations\n",
    "    corr_matrix = pd.DataFrame(index=gene_columns, columns=morpho_columns)\n",
    "\n",
    "    # Calculate Spearman correlation for each gene-morphological feature pair\n",
    "    for gene in gene_columns:\n",
    "        for morpho in morpho_columns:\n",
    "            corr, _ = spearmanr(gene_expr_df[gene], morpho_df[morpho])\n",
    "            corr_matrix.at[gene, morpho] = corr\n",
    "\n",
    "    # Convert the correlation matrix to numeric values\n",
    "    corr_matrix = corr_matrix.astype(float)\n",
    "\n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072fbff-4aa2-4eb2-9439-c6cb8b7a6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_parent = sc.read_h5ad('Shape_500.h5ad')\n",
    "ad_parent = ad_parent[ad_parent.obs.updated_celltype == 'Microglia']\n",
    "\n",
    "ad_list = []\n",
    "for batch in ad_parent.obs.batchID.unique():\n",
    "    ad_viz = ad_parent[ad_parent.obs.batchID == batch].copy()\n",
    "    \n",
    "    total = pd.read_csv(f\"transcript_out/{batch}_nuc_y_non_nuc.csv\",index_col=0)\n",
    "    non_nuc = pd.read_csv(f\"transcript_out/{batch}_non_nuc.csv\",index_col=0)\n",
    "    \n",
    "    ad_viz.layers['total_counts'] = total[ad_viz.var_names.intersection(total.columns)].to_numpy()\n",
    "    ad_viz.layers['non_nuc_counts'] = non_nuc[ad_viz.var_names.intersection(non_nuc.columns)].to_numpy()\n",
    "    \n",
    "    ad_viz.layers['nuc_counts'] = ad_viz.layers['total_counts'] - ad_viz.layers['non_nuc_counts']\n",
    "    \n",
    "    ad_list.append(ad_viz)\n",
    "    \n",
    "combined_adata = anndata.concat(ad_list, axis=0)\n",
    "adata = combined_adata.copy()\n",
    "adata_s = combined_adata.copy()\n",
    "adata_b = combined_adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410e532-bd58-49c0-bc01-855327e0cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_s.X = adata_s.layers['nuc_counts']\n",
    "sc.pp.normalize_total(adata_s,target_sum=1e4)\n",
    "sc.pp.log1p(adata_s)\n",
    "\n",
    "adata_b.X = adata_b.layers['non_nuc_counts']\n",
    "sc.pp.normalize_total(adata_b,target_sum=1e4)\n",
    "sc.pp.log1p(adata_b)\n",
    "\n",
    "adata.X = adata.layers['total_counts']\n",
    "sc.pp.normalize_total(adata,target_sum=1e4)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad84a4-c3aa-4724-9622-8b0dad8e0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_full = adata_s[(adata_s.obs.morph_leiden.isin([4]))]\n",
    "dendrites_full = adata_b[(adata_b.obs.morph_leiden.isin([4]))]\n",
    "\n",
    "soma_young = adata_s[(adata_s.obs.morph_leiden.isin([4]))& (adata_s.obs.Age.isin(['3']))]\n",
    "dendrites_young = adata_b[(adata_b.obs.morph_leiden.isin([4]))& (adata_b.obs.Age.isin(['3']))]\n",
    "\n",
    "soma_old = adata_s[(adata_s.obs.morph_leiden.isin([4]))& (adata_s.obs.Age.isin(['24']))]\n",
    "dendrites_old = adata_b[(adata_b.obs.morph_leiden.isin([4]))& (adata_b.obs.Age.isin(['24']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ed3c5-3d90-430e-a3fa-a6fea00a1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = differential_expression(soma_old, dendrites_old)\n",
    "soma_old_genes, branches_old_genes = plot_volcano(df_old, pval_col_suffix='_pvals_adj',xlims=[-10,10],sig_lfc=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1da37-4cfa-42c9-9c1b-6feb1beee10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_young = differential_expression(soma_young, dendrites_young)\n",
    "soma_young_genes, branches_young_genes = plot_volcano(df_young, pval_col_suffix='_pvals_adj',xlims=[-10,10],sig_lfc=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd872a-24ff-4365-ad3e-b28adc194df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = differential_expression(soma_full, dendrites_full)\n",
    "soma_full_genes, branches_full_genes = plot_volcano(df_full, pval_col_suffix='_pvals_adj',xlims=[-10,10],sig_lfc=1,figsize=(15,10),savefig='Branches_over_soma.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec00bf-ab64-4ced-8869-9dad379d2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichr_results = gp.enrichr(\n",
    "    gene_list=soma_full_genes, \n",
    "    gene_sets='GO_Cellular_Component_2023',  # Database for cellular compartments\n",
    "    organism='Mouse',  # Organism (can be 'Mouse', 'Human', etc.)\n",
    "    )\n",
    "\n",
    "    # Convert the results to a pandas DataFrame\n",
    "df_results = enrichr_results.results\n",
    "gp.barplot(enrichr_results.res2d, title='GO Enrichment', cutoff=0.05, figsize=(6,5),ofname=f'soma_enriched_compartment.pdf')\n",
    "\n",
    "enrichr_results = gp.enrichr(\n",
    "    gene_list=branches_full_genes, \n",
    "    gene_sets='GO_Cellular_Component_2023',  # Database for cellular compartments\n",
    "    organism='Mouse',  # Organism (can be 'Mouse', 'Human', etc.)\n",
    "    )\n",
    "\n",
    "    # Convert the results to a pandas DataFrame\n",
    "df_results = enrichr_results.results\n",
    "gp.barplot(enrichr_results.res2d, title='GO Enrichment', cutoff=0.05, figsize=(6,5),ofname=f'branch_enriched_compartment.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0dbeb7-8256-4b48-87b2-b5faa3d406ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_age = set(branches_young_genes) - set(branches_old_genes)\n",
    "branches_age = [i for i in branches_age]\n",
    "\n",
    "branches_common = set(branches_young_genes) & set(branches_old_genes)\n",
    "branches_common = [i for i in branches_common]\n",
    "\n",
    "soma_age = set(soma_young_genes) - set(soma_old_genes)\n",
    "soma_age = [i for i in soma_age]\n",
    "\n",
    "soma_common = set(soma_young_genes) & set(soma_old_genes)\n",
    "soma_common = [i for i in soma_common]\n",
    "\n",
    "print(f\"Branches young: {len(branches_young_genes)}; Branches old: {len(branches_old_genes)}; Soma young: {len(soma_young_genes)}; Soma old:{len(soma_old_genes)}\")\n",
    "print(f\"Branches common: {len(branches_common)}; Soma common: {len(soma_common)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a11fc-38fb-4faa-80f3-a38a0b5ce865",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = list(adata.obs.columns).index('Cell Area')  # Add 1 to include the column itself\n",
    "columns_after_specific = adata.obs.iloc[:, start_index:].values\n",
    "\n",
    "morphological_columns = adata.obs.columns[start_index:]\n",
    "\n",
    "features = set(morphological_columns[:-6].tolist()) - set(['Ramification Index', 'Radius of Influence'])\n",
    "features = [i for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09ca63-1cb1-4d54-be6b-8888e4819461",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_branches = calculate_spearman_corr(adata, branches_common, features)\n",
    "corr_matrix_soma = calculate_spearman_corr(adata, soma_common, features)\n",
    "\n",
    "corr_matrix_branches_3 = calculate_spearman_corr(adata[adata.obs.Age.isin(['3'])], branches_common, features)\n",
    "corr_matrix_branches_24 = calculate_spearman_corr(adata[adata.obs.Age.isin(['24'])], branches_common, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26e91d-46bd-44f6-bd2c-ddc5f035b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_correlation(soma_corr_matrix, branch_corr_matrix,variable='Region',output_pdf=None):\n",
    "    \n",
    "    if variable == 'Region':\n",
    "        # Calculate mean correlation for each morphological feature across all genes\n",
    "        avg_soma_corr = soma_corr_matrix.mean(axis=0)  # Mean correlation for soma-enriched genes\n",
    "        avg_branch_corr = branch_corr_matrix.mean(axis=0)  # Mean correlation for branch-enriched genes\n",
    "\n",
    "        # Combine the averages into a DataFrame for easy plotting\n",
    "        avg_corr_df = pd.DataFrame({\n",
    "        'Branch': avg_branch_corr,\n",
    "        'Soma': avg_soma_corr,\n",
    "        })\n",
    "\n",
    "        # Sort the DataFrame by branch correlations in descending order\n",
    "        avg_corr_df = avg_corr_df.sort_values(by='Branch', ascending=False)\n",
    "\n",
    "    # Create a bar plot with the average correlations\n",
    "        avg_corr_df.plot(kind='bar', figsize=(10, 6))\n",
    "        plt.title('Average Spearman Correlation by Morphological Feature (Sorted by Branch Correlation)')\n",
    "        plt.ylabel('Average Correlation')\n",
    "        plt.xlabel('Morphological Features')\n",
    "        plt.xticks(rotation=90, ha='right')\n",
    "        plt.tight_layout()\n",
    "        if output_pdf:\n",
    "            plt.savefig(f\"{output_pdf}{variable}_spearman_correlation.pdf\",format='pdf')\n",
    "        plt.show()\n",
    "    elif variable == 'Age':\n",
    "        avg_soma_corr = soma_corr_matrix.mean(axis=0)  # Mean correlation for soma-enriched genes\n",
    "        avg_branch_corr = branch_corr_matrix.mean(axis=0)  # Mean correlation for branch-enriched genes\n",
    "\n",
    "        # Combine the averages into a DataFrame for easy plotting\n",
    "        avg_corr_df = pd.DataFrame({\n",
    "        '3m': avg_branch_corr,\n",
    "        '24': avg_soma_corr,\n",
    "        })\n",
    "\n",
    "        # Sort the DataFrame by branch correlations in descending order\n",
    "        avg_corr_df = avg_corr_df.sort_values(by='3m', ascending=False)\n",
    "\n",
    "    # Create a bar plot with the average correlations\n",
    "        avg_corr_df.plot(kind='bar', figsize=(10, 6))\n",
    "        plt.title('Average Spearman Correlation by Morphological Feature (Sorted by 3m Correlation)')\n",
    "        plt.ylabel('Average Correlation')\n",
    "        plt.xlabel('Morphological Features')\n",
    "        plt.xticks(rotation=90, ha='right')\n",
    "        plt.tight_layout()\n",
    "        if output_pdf:\n",
    "            plt.savefig(f\"{output_pdf}{variable}_spearman_correlation.pdf\",format='pdf')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Make sure you are trying to plot transcript location or Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af333bf-e642-4ca1-9c18-c5c501bcb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_correlation(corr_matrix_soma,corr_matrix_branches,variable='Region',output_pdf='figures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55399cb4-5b08-4d1b-952a-7cb1310957cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_correlation(corr_matrix_branches_24,corr_matrix_branches_3,variable='Age',output_pdf='figures/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7b97a-12fd-42be-a0ae-78a0839777b8",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f5253-df25-4d5a-8330-64f02efaeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc0c4f-6572-49f2-ba8d-ace69d8a1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_adata_rf_list(adata_list, use_grid_search=False, use_random_search=False, output_pdf=None):\n",
    "    \"\"\"\n",
    "    Analyze multiple AnnData objects using Random Forest classifiers. For each AnnData, \n",
    "    it plots the ROC-AUC curves on the same axis and outputs the feature importances for the genes in all models.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata_list: List of AnnData objects to analyze.\n",
    "    - use_grid_search: Boolean indicating whether to use Grid Search for hyperparameter tuning.\n",
    "    - use_random_search: Boolean indicating whether to use Random Search for hyperparameter tuning.\n",
    "    \n",
    "    Returns:\n",
    "    - feature_importances_mdi_dict: A dictionary of MDI (Mean Decrease in Impurity) feature importances for each AnnData.\n",
    "    - feature_importances_perm_dict: A dictionary of permutation feature importances for each AnnData.\n",
    "    \"\"\"\n",
    "    # To store MDI and permutation importances for each AnnData\n",
    "    feature_importances_mdi_dict = {}\n",
    "    feature_importances_perm_dict = {}\n",
    "\n",
    "    plt.figure(figsize=(10, 8))  # Initialize a single figure for all ROC curves\n",
    "    age_list = ['3 month', '24 month']\n",
    "    \n",
    "    for idx, adata in enumerate(adata_list):\n",
    "        print(f\"Analyzing AnnData {idx + 1}/{len(adata_list)}\")\n",
    "        \n",
    "        # Extract features and labels from the adata object\n",
    "        X = adata.X\n",
    "        y = adata.obs['sub_morph'].values\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_binary = label_encoder.fit_transform(y)\n",
    "        print(f\"With the binary encoding sub_morph:{y[0]} is equivalent to {y_binary[0]}\")\n",
    "\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val1, y_train, y_val1 = train_test_split(\n",
    "            X.toarray() if hasattr(X, \"toarray\") else X, \n",
    "            y_binary, \n",
    "            test_size=0.2, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Define the Random Forest model\n",
    "        rf_model = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        # Hyperparameter tuning (optional)\n",
    "        if use_grid_search:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300, 400],\n",
    "                'max_depth': [10, 20, 30, None],\n",
    "                'min_samples_split': [2, 5, 10, 20],\n",
    "                'min_samples_leaf': [1, 2, 4, 8],\n",
    "                'bootstrap': [True, False]\n",
    "            }\n",
    "            grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                                       cv=3, n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            rf_model = grid_search.best_estimator_\n",
    "            print(f\"Best parameters (Grid Search): {grid_search.best_params_}\")\n",
    "        \n",
    "        elif use_random_search:\n",
    "            param_dist = {\n",
    "                'n_estimators': randint(100, 1000),\n",
    "                'max_depth': [10, 20, 30, None],\n",
    "                'min_samples_split': randint(2, 11),\n",
    "                'min_samples_leaf': randint(1, 5),\n",
    "                'bootstrap': [True, False]\n",
    "            }\n",
    "            random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, \n",
    "                                               n_iter=100, cv=3, n_jobs=-1, verbose=2, random_state=42, scoring='roc_auc')\n",
    "            random_search.fit(X_train, y_train)\n",
    "            rf_model = random_search.best_estimator_\n",
    "            print(f\"Best parameters (Random Search): {random_search.best_params_}\")\n",
    "        \n",
    "        else:\n",
    "            # Train the Random Forest model without tuning\n",
    "            rf_model = RandomForestClassifier(\n",
    "                n_estimators=200, \n",
    "                max_depth=20, \n",
    "                min_samples_split=5, \n",
    "                min_samples_leaf=2, \n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get ROC-AUC scores and predictions\n",
    "        y_train_pred_prob = rf_model.predict_proba(X_train)[:, 1]\n",
    "        y_val1_pred_prob = rf_model.predict_proba(X_val1)[:, 1]\n",
    "        \n",
    "        roc_auc_train = roc_auc_score(y_train, y_train_pred_prob)\n",
    "        roc_auc_val1 = roc_auc_score(y_val1, y_val1_pred_prob)\n",
    "        \n",
    "        print(f\"Random Forest - ROC AUC (Training): {roc_auc_train:.4f}\")\n",
    "        print(f\"Random Forest - ROC AUC (Validation 1): {roc_auc_val1:.4f}\")\n",
    "\n",
    "        # Plot ROC curve on the same figure for each AnnData\n",
    "        # Training set ROC curve\n",
    "        fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_prob)\n",
    "        plt.plot(fpr_train, tpr_train, label=f'{age_list[idx]} (Training AUC = {roc_auc_train:.2f})')\n",
    "\n",
    "        # Validation set ROC curve\n",
    "        fpr_val1, tpr_val1, _ = roc_curve(y_val1, y_val1_pred_prob)\n",
    "        plt.plot(fpr_val1, tpr_val1, label=f'{age_list[idx]} (Validation AUC = {roc_auc_val1:.2f})')\n",
    "\n",
    "        # Get feature names\n",
    "        feature_names = adata.var_names\n",
    "        \n",
    "        # Store the feature importances (MDI) for this AnnData\n",
    "        feature_importances_mdi = rf_model.feature_importances_\n",
    "        feature_importances_mdi_df = pd.DataFrame({\n",
    "        'Gene': feature_names,\n",
    "        'Importance': feature_importances_mdi\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        feature_importances_mdi_dict[f'AnnData_{idx + 1}'] = feature_importances_mdi_df\n",
    "\n",
    "        \n",
    "        # Calculate permutation importance\n",
    "        perm_importance = permutation_importance(rf_model, X_val1, y_val1, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "        perm_importance_df = pd.DataFrame({\n",
    "        'Gene': feature_names,\n",
    "        'Importance': perm_importance.importances_mean\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        \n",
    "        feature_importances_perm_dict[f'AnnData_{idx + 1}'] = perm_importance_df\n",
    "    \n",
    "    # Finalize the ROC curve plot\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves - Random Forest (All AnnDatas)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if output_pdf:\n",
    "        plt.savefig(output_pdf, format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "    return feature_importances_mdi_dict, feature_importances_perm_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc7c84-c10c-4dac-909f-598b8971e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_test = combined_adata.copy()\n",
    "\n",
    "\n",
    "ad_test.X = ad_test.layers['total_counts'].copy()\n",
    "\n",
    "binarize_morphs = {\n",
    "    0:'Transition',\n",
    "    1:'Ramified',\n",
    "    2:'Activated',\n",
    "    3:'Activated',\n",
    "    4:'Ramified'\n",
    "}\n",
    "\n",
    "ad_test.obs['sub_morph'] = ad_test.obs.morph_leiden.map(binarize_morphs)\n",
    "adata_3 = ad_test[(ad_test.obs.sub_morph.isin(['Activated','Ramified'])) & (ad_test.obs.Age == '3')]\n",
    "adata_24 = ad_test[(ad_test.obs.sub_morph.isin(['Activated','Ramified'])) & (ad_test.obs.Age == '24')]\n",
    "adata_3 = adata_3[:,branches_common]\n",
    "adata_24 = adata_24[:,branches_common]\n",
    "\n",
    "sc.pp.normalize_total(adata_3,target_sum=1e4)\n",
    "sc.pp.log1p(adata_3)\n",
    "\n",
    "sc.pp.normalize_total(adata_24,target_sum=1e4)\n",
    "sc.pp.log1p(adata_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5ae57-e66c-44d2-accf-d580a83a0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_mdi, importances_perm = analyze_adata_rf_list([adata_3,adata_24],use_random_search=True,output_pdf='figures/AUC_ROC_by_age.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62216a2d-7d93-46cb-bb0f-d0befea81ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_1 = importances_mdi['AnnData_1']\n",
    "importance_2 = importances_mdi['AnnData_2']\n",
    "    \n",
    "    # Merge the two DataFrames on 'Gene' to align the genes\n",
    "merged_importances = pd.merge(importance_1, importance_2, on='Gene', suffixes=('_AnnData_1', '_AnnData_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f15419-95fe-4a16-851d-b35ca5076b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_comparison(feature_importances_dict,output_pdf=None):\n",
    "    # Extract feature importance DataFrames for AnnData_1 and AnnData_2\n",
    "    importance_1 = feature_importances_dict['AnnData_1']\n",
    "    importance_2 = feature_importances_dict['AnnData_2']\n",
    "    \n",
    "    # Merge the two DataFrames on 'Gene' to align the genes\n",
    "    merged_importances = pd.merge(importance_1, importance_2, on='Gene', suffixes=('_AnnData_1', '_AnnData_2'))\n",
    "    \n",
    "    # Plot the scatter plot comparing the importances\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(merged_importances['Importance_AnnData_1'], merged_importances['Importance_AnnData_2'], alpha=0.7)\n",
    "    \n",
    "    # Add a y = x diagonal line\n",
    "    max_val = max(merged_importances[['Importance_AnnData_1', 'Importance_AnnData_2']].max())\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--', label='y=x')\n",
    "    \n",
    "    # Label the second highest importance value for each AnnData\n",
    "    # Get the second highest importance for AnnData_1 and AnnData_2\n",
    "    highest = importance_1.nlargest(2,'Importance').iloc[0]\n",
    "    second_highest_1 = importance_1.nlargest(2, 'Importance').iloc[1]\n",
    "    second_highest_2 = importance_2.nlargest(2, 'Importance').iloc[1]\n",
    "    \n",
    "    plt.annotate(highest['Gene'], \n",
    "                 xy=(highest['Importance'], merged_importances.loc[merged_importances['Gene'] == highest['Gene'], 'Importance_AnnData_2'].values[0]), \n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=10, color='black')\n",
    "    \n",
    "    # Annotate second-highest gene for AnnData_1\n",
    "    plt.annotate(second_highest_1['Gene'], \n",
    "                 xy=(second_highest_1['Importance'], merged_importances.loc[merged_importances['Gene'] == second_highest_1['Gene'], 'Importance_AnnData_2'].values[0]), \n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=10, color='black')\n",
    "\n",
    "    # Annotate second-highest gene for AnnData_2\n",
    "    plt.annotate(second_highest_2['Gene'], \n",
    "                 xy=(merged_importances.loc[merged_importances['Gene'] == second_highest_2['Gene'], 'Importance_AnnData_1'].values[0], second_highest_2['Importance']), \n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=10, color='black')\n",
    "    \n",
    "    # Plot customizations\n",
    "    plt.xlabel('Feature Importance (AnnData 1)')\n",
    "    plt.ylabel('Feature Importance (AnnData 2)')\n",
    "    plt.title('Comparison of Feature Importances Between AnnData 1 and AnnData 2')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    if output_pdf:\n",
    "        plt.savefig(output_pdf,format='pdf')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d281b-e9d9-4eda-93c7-c837986453d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_comparison(importances_mdi,output_pdf='figures/top_genes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e8e6c-9899-4317-a9c1-332dd36a981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "from nheatmap import nhm\n",
    "\n",
    "def create_pseudobulk(adata, cluster_col='morph_leiden', batch_col='batchID'):\n",
    "    # Create a unique identifier for each cluster-batch pair\n",
    "    adata.obs['pseudobulk_id'] = adata.obs[cluster_col].astype(str) + '.' + adata.obs[batch_col].astype(str)\n",
    "    \n",
    "    # Group the data by the pseudobulk_id\n",
    "    groups = adata.obs['pseudobulk_id'].unique()\n",
    "    pseudobulk_data = []\n",
    "    pseudobulk_obs = []\n",
    "    \n",
    "    for group in groups:\n",
    "        # Subset the data for each group\n",
    "        group_mask = adata.obs['pseudobulk_id'] == group\n",
    "        group_data = adata[group_mask, :].X.mean(axis=0)  # Sum the expression values\n",
    "        pseudobulk_data.append(group_data)\n",
    "        \n",
    "        # Collect the metadata\n",
    "        cluster, batch= group.split('.')\n",
    "        pseudobulk_obs.append({'pseudobulk_id': group, cluster_col: cluster, batch_col: batch, 'Age': batch.split('-')[0] , 'Sex': batch.split('-')[2]})\n",
    "    \n",
    "    # Convert the list to a numpy array\n",
    "    pseudobulk_data = np.array(pseudobulk_data)\n",
    "    #print(pseudobulk_data[:,0,:].shape)\n",
    "    #print(pseudobulk_data.shape)\n",
    "    \n",
    "    # Create a new AnnData object for the pseudobulked data\n",
    "    pseudobulk_adata = sc.AnnData(X=pseudobulk_data)\n",
    "    \n",
    "    # Add the metadata\n",
    "    pseudobulk_adata.obs = pd.DataFrame(pseudobulk_obs)\n",
    "    \n",
    "    # Copy variable names (genes) from the original data\n",
    "    pseudobulk_adata.var = adata.var.copy()\n",
    "    \n",
    "    return pseudobulk_adata\n",
    "\n",
    "def concatenate_nuclear_non_nuclear(adata_nuclear, adata_non_nuclear):\n",
    "    \"\"\"\n",
    "    Concatenates two AnnData objects (nuclear and non-nuclear) and adds a metadata column \n",
    "    distinguishing between them.\n",
    "\n",
    "    Parameters:\n",
    "    - adata_nuclear: AnnData object for nuclear counts\n",
    "    - adata_non_nuclear: AnnData object for non-nuclear counts\n",
    "\n",
    "    Returns:\n",
    "    - A concatenated AnnData object with an additional 'Count_Type' column in obs\n",
    "    \"\"\"\n",
    "\n",
    "    # Add a new column 'Count_Type' to distinguish the two datasets\n",
    "    adata_nuclear.obs['Location_of_Transcripts'] = 'soma'\n",
    "    adata_non_nuclear.obs['Location_of_Transcripts'] = 'non-soma'\n",
    "\n",
    "    # Concatenate the two AnnData objects\n",
    "    adata_combined = adata_nuclear.concatenate(adata_non_nuclear, join='outer')\n",
    "\n",
    "    return adata_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6932a4e-194f-4c05-a47b-5b9d351d509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_ad = soma_young.concatenate(soma_old, join='outer')\n",
    "branch_ad = dendrites_young.concatenate(dendrites_old, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127d3c9-347d-4709-bab2-4b9e969042da",
   "metadata": {},
   "outputs": [],
   "source": [
    "young_genes = set(soma_young_genes[:10] + branches_young_genes[:15])\n",
    "young_genes = [i for i in young_genes]\n",
    "\n",
    "old_genes = set(soma_old_genes[:10] + branches_old_genes[:15])\n",
    "old_genes = [i for i in old_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5d555-1362-43d5-8125-d96abe2e217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_young = concatenate_nuclear_non_nuclear(soma_young,dendrites_young)\n",
    "\n",
    "pseudo = create_pseudobulk(total_young[:,young_genes],cluster_col='Location_of_Transcripts')\n",
    "\n",
    "counts_matrix = pseudo.X\n",
    "gene_names = pseudo.var_names\n",
    "cell_names = pseudo.obs_names\n",
    "\n",
    "# Create the DataFrame with obs_names as rows and var_names as columns\n",
    "counts_df = pd.DataFrame(data=counts_matrix, index=cell_names, columns=gene_names)\n",
    "zscored_df = counts_df.apply(zscore, axis=0)\n",
    "\n",
    "subset_df = zscored_df\n",
    "\n",
    "dfc = pseudo.obs.loc[:,['Location_of_Transcripts','Age']]\n",
    "dfr = pseudo.obs.loc[:,['Location_of_Transcripts']]\n",
    "\n",
    "dfr_sorted = dfr.sort_values(by='Location_of_Transcripts')\n",
    "\n",
    "# Reorder `subset_df` to match the order of `dfr_sorted`\n",
    "subset_df_reordered = subset_df.loc[dfr_sorted.index]\n",
    "\n",
    "cmaps={'batchID':'Location_of_Transcripts', 'Age':'RdYlGn', 'Sex':'inferno',\n",
    "        'PC score':'gist_heat', 'PC score 2':'rainbow'}\n",
    "\n",
    "g = nhm(data=subset_df.T, dfc=dfc, figsize=(10, 10), linewidths=0, cmaps=cmaps, showxticks=False,cmapCenter='coolwarm')\n",
    "g.hcluster(method='single', metric='cosine', optimal_ordering=False)\n",
    "fig, plots = g.run()\n",
    "fig.savefig('figures/young_gene_clustering.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39101c-04dc-4b27-bc5e-246c86f958ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_old = concatenate_nuclear_non_nuclear(soma_old,dendrites_old)\n",
    "\n",
    "pseudo = create_pseudobulk(total_old[:,old_genes],cluster_col='Location_of_Transcripts')\n",
    "\n",
    "counts_matrix = pseudo.X\n",
    "gene_names = pseudo.var_names\n",
    "cell_names = pseudo.obs_names\n",
    "\n",
    "# Create the DataFrame with obs_names as rows and var_names as columns\n",
    "counts_df = pd.DataFrame(data=counts_matrix, index=cell_names, columns=gene_names)\n",
    "zscored_df = counts_df.apply(zscore, axis=0)\n",
    "\n",
    "subset_df = zscored_df\n",
    "\n",
    "dfc = pseudo.obs.loc[:,['Location_of_Transcripts','Age']]\n",
    "dfr = pseudo.obs.loc[:,['Location_of_Transcripts']]\n",
    "\n",
    "dfr_sorted = dfr.sort_values(by='Location_of_Transcripts')\n",
    "\n",
    "# Reorder `subset_df` to match the order of `dfr_sorted`\n",
    "subset_df_reordered = subset_df.loc[dfr_sorted.index]\n",
    "\n",
    "cmaps={'batchID':'Location_of_Transcripts', 'Age':'RdYlGn', 'Sex':'inferno',\n",
    "        'PC score':'gist_heat', 'PC score 2':'rainbow'}\n",
    "\n",
    "g = nhm(data=subset_df.T, dfc=dfc, figsize=(10, 10), linewidths=0, cmaps=cmaps, showxticks=False,cmapCenter='coolwarm')\n",
    "g.hcluster(method='single', metric='cosine', optimal_ordering=False)\n",
    "fig, plots = g.run()\n",
    "fig.savefig('figures/old_gene_clustering.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
