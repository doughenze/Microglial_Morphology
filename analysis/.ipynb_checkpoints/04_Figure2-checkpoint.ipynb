{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a8bc81-d6e1-4f63-926a-d194e4b08e6a",
   "metadata": {},
   "source": [
    "# This notebook must be run with the Vizgen_2 conda environment within the Vizgen.sif singularity container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8eb0b4-d106-4108-aa48-d00ac858eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "import Mapping\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "from skimage.morphology import disk, opening, closing\n",
    "from scipy.ndimage import binary_fill_holes, label, distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries, watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from skimage.segmentation import watershed\n",
    "import anndata\n",
    "from adjustText import adjust_text\n",
    "\n",
    "import Mapping\n",
    "import os\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import igraph as ig\n",
    "#import leidenalg\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import seaborn as sns\n",
    "import tifffile\n",
    "import umap\n",
    "from anndata import AnnData as ad\n",
    "from matplotlib import patches as mpatches\n",
    "#from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "from shapely.affinity import translate\n",
    "from shapely.geometry import Polygon, MultiPolygon, box, shape\n",
    "from skimage import img_as_bool, img_as_ubyte\n",
    "from skimage.measure import find_contours, regionprops, regionprops_table\n",
    "from skimage.morphology import skeletonize, opening\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.segmentation import find_boundaries\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "import gseapy as gp\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a37007-4534-4782-af34-35ccb9562720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_cells_from_cluster(data, cluster_id,column='leiden', num_cells=9,raw=False,random_state=35, conversion_rate=1.0, micron_length=50, output_pdf=None):\n",
    "    \"\"\"\n",
    "    Plot random cells from the specified Leiden cluster.\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): DataFrame containing 'batchID', 'cell_label', and 'leiden_cluster'.\n",
    "    - cluster_id (int): The Leiden cluster ID to visualize.\n",
    "    - num_cells (int): Number of cells to display, default is 4.\n",
    "    \"\"\"\n",
    "    # Filter data for the specified cluster\n",
    "    cluster_data = data[data[column] == cluster_id]\n",
    "    #print(cluster_data)\n",
    "    \n",
    "    # Randomly select cells if there are more than num_cells\n",
    "    if len(cluster_data) > num_cells:\n",
    "        cluster_data = cluster_data.sample(n=num_cells, random_state=random_state)\n",
    "    \n",
    "    # Create a grid plot\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ax, (_, row) in zip(axes, cluster_data.iterrows()):\n",
    "        print(row['batchID'])\n",
    "        image = load_label_image(row['batchID'], row['x'], row['y'], raw)\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Batch: {row['batchID']}, x: {row['x']}, y:{row['y']}\")\n",
    "        add_scale_bar(ax, conversion_rate, micron_length, location=(10, image.shape[0] - 20))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_pdf:\n",
    "        plt.savefig(output_pdf, format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def extract_sub_image_with_padding(image, bbox, padding=10):\n",
    "    min_row, min_col, max_row, max_col = bbox\n",
    "    min_row = max(min_row - padding, 0)\n",
    "    min_col = max(min_col - padding, 0)\n",
    "    max_row = min(max_row + padding, image.shape[0])\n",
    "    max_col = min(max_col + padding, image.shape[1])\n",
    "    return image[min_row:max_row, min_col:max_col], (min_row, min_col)\n",
    "\n",
    "def add_scale_bar(ax, conversion_rate, micron_length, color='red', location=(10, 10), thickness=50, fontsize=12):\n",
    "    \"\"\"\n",
    "    Add a scale bar to the given axis.\n",
    "\n",
    "    Args:\n",
    "    - ax: The axis on which to draw the scale bar.\n",
    "    - conversion_rate: The pixel-to-micron conversion factor (pixels per micron).\n",
    "    - micron_length: The length of the scale bar in microns.\n",
    "    - color: The color of the scale bar.\n",
    "    - location: A tuple specifying the (x, y) location of the scale bar.\n",
    "    - thickness: The thickness of the scale bar in pixels.\n",
    "    \"\"\"\n",
    "    # Calculate the length of the scale bar in pixels\n",
    "    pixel_length = conversion_rate * micron_length\n",
    "    \n",
    "    # Create a rectangle for the scale bar\n",
    "    scale_bar = patches.Rectangle(location, pixel_length, thickness, linewidth=0, edgecolor=color, facecolor=color)\n",
    "    \n",
    "    # Add the scale bar to the plot\n",
    "    ax.add_patch(scale_bar)\n",
    "    text_x = location[0] + pixel_length + 10  # Place text to the right of the scale bar\n",
    "    text_y = location[1] + thickness / 2      # Vertically center the text with the scale bar\n",
    "    ax.text(text_x, text_y, f'{micron_length} Î¼m', color=color, fontsize=fontsize, va='center')\n",
    "\n",
    "\n",
    "def load_label_image(batchID, x_ax, y_ax,raw=False):\n",
    "    root = '/hpc/projects/group.quake/doug/Shapes_Spatial/'\n",
    "    \n",
    "    transform_file = f'{root}{batchID}/images/micron_to_mosaic_pixel_transform.csv'\n",
    "    transform_df = pd.read_table(transform_file, sep=' ', header=None)\n",
    "    transformation_matrix = transform_df.values\n",
    "    \n",
    "    x_ax = round(x_ax * transformation_matrix[0,0] + transformation_matrix[0,2])\n",
    "    y_ax = round(y_ax * transformation_matrix[1,1] + transformation_matrix[1,2])\n",
    "    \n",
    "    print(f'load {batchID}')\n",
    "    raw_im = Mapping.load_tiff_image(root + batchID + '/binary_image.tif')\n",
    "    \n",
    "    box_size = 500\n",
    "    x_start = x_ax - box_size\n",
    "    x_end = x_ax + box_size\n",
    "    y_start = y_ax - box_size\n",
    "    y_end = y_ax + box_size\n",
    "    \n",
    "    # Extract the sub-image, ensuring the indices are within bounds\n",
    "    sub_image = np.zeros((2*box_size, 2*box_size), dtype=raw_im.dtype)\n",
    "    \n",
    "    raw_x_start = max(x_start, 0)\n",
    "    raw_x_end = min(x_end, raw_im.shape[1])\n",
    "    raw_y_start = max(y_start, 0)\n",
    "    raw_y_end = min(y_end, raw_im.shape[0])\n",
    "    \n",
    "    sub_x_start = max(0, -x_start)\n",
    "    sub_x_end = sub_x_start + (raw_x_end - raw_x_start)\n",
    "    sub_y_start = max(0, -y_start)\n",
    "    sub_y_end = sub_y_start + (raw_y_end - raw_y_start)\n",
    "    \n",
    "    sub_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end] = raw_im[raw_y_start:raw_y_end, raw_x_start:raw_x_end]\n",
    "    \n",
    "    if raw==True:\n",
    "        return sub_image\n",
    "    \n",
    "    #sub_test = raw_im[(y_ax-500):(y_ax+500), (x_ax-500):(x_ax+500)]\n",
    "    #print(sub_test.shape)\n",
    "    \n",
    "    #if sub_test.size == 0:\n",
    "     #   return np.zeros((20,20))\n",
    "    \n",
    "    subtract = cv2.fastNlMeansDenoising(sub_image)\n",
    "    pre = cv2.adaptiveThreshold((255 - subtract), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 75, 2)\n",
    "\n",
    "    opened = opening(255 - pre, disk(3))\n",
    "    pre = closing(opened, disk(3))\n",
    "\n",
    "    filled_image = binary_fill_holes(pre)\n",
    "\n",
    "    labeled_array, num_features = label(filled_image)\n",
    "    \n",
    "    point = (500, 500)\n",
    "\n",
    "    regions = regionprops(labeled_array)\n",
    "\n",
    "    largest_component_label = None\n",
    "    max_area = 0\n",
    "\n",
    "    for region in regions:\n",
    "        if region.area > 500:\n",
    "            # Find the boundary of the component\n",
    "            boundary = find_boundaries(labeled_array == region.label, mode='outer')\n",
    "            boundary_coords = np.column_stack(np.where(boundary))\n",
    "\n",
    "            # Calculate the distance from the point to the boundary\n",
    "            distances = np.linalg.norm(boundary_coords - np.array(point), axis=1)\n",
    "            min_dist = np.min(distances)\n",
    "\n",
    "            if min_dist < 100:\n",
    "                if region.area > max_area:\n",
    "                    max_area = region.area\n",
    "                    largest_component_label = region.label\n",
    "\n",
    "    if largest_component_label is not None:\n",
    "        isolated_component = labeled_array == largest_component_label\n",
    "\n",
    "        label_image = np.zeros_like(labeled_array)\n",
    "        label_image[isolated_component] = 1\n",
    "        return label_image\n",
    "        \n",
    "    return sub_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da973f79-837e-4284-8512-7ab02ce3e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ad = sc.read_h5ad('Transciptomic_labels_and_morphology_labels_full.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043ac37-d17c-4832-ae09-22cc038d1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(new_ad, basis = 'X_umap_shapes',color=['ordered_morph','sub_mic'],save='morphology.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06973d33-f2ad-486c-9155-0a7e1f616f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_to_micron = pd.read_csv('/3-mo-female-1-rev2/images/micron_to_mosaic_pixel_transform.csv',delimiter=' ').iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11328de2-5ff2-4539-ada5-e89601546065",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_cells_from_cluster(new_ad.obs, cluster_id='0', column='ordered_morph', raw=True,conversion_rate=mosaic_to_micron,output_pdf='phagocytic_0_examples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c8ee8-907a-4599-8256-831b85224994",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_cells_from_cluster(new_ad.obs, cluster_id='1', column='ordered_morph', raw=True,conversion_rate=mosaic_to_micron,output_pdf='phagocytic_1_examples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a657e74-9808-48c5-a5bf-180448308bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_cells_from_cluster(new_ad.obs, cluster_id='2', column='ordered_morph', raw=True,conversion_rate=mosaic_to_micron,output_pdf='ramified_2_examples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf03bc-6f8c-43fe-b37b-85aab4af4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_cells_from_cluster(new_ad.obs, cluster_id='3', column='ordered_morph', raw=True,conversion_rate=mosaic_to_micron,output_pdf='ramified_3_examples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b9e8b-2053-4e8f-b8d5-fe8572c139cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_cells_from_cluster(new_ad.obs, cluster_id='4', column='ordered_morph', raw=True,conversion_rate=mosaic_to_micron,output_pdf='ramified_4_examples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8495f-aa8a-4625-a870-b2900474be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = list(new_ad.obs.columns).index('Cell Area')  # Add 1 to include the column itself\n",
    "columns_after_specific = new_ad.obs.iloc[:, start_index:].values\n",
    "\n",
    "morphological_columns = new_ad.obs.columns[start_index:]\n",
    "\n",
    "features = morphological_columns[:-11].tolist()\n",
    "\n",
    "features_set = set(features) - set(['Radius of Influence'])\n",
    "features = [i for i in features_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c23db-0c53-41ad-a7cd-1fd30bb1b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ad.obs['ordered morph'] = new_ad.obs['ordered_morph'].astype(str).sort_values()\n",
    "\n",
    "fig, axes = plt.subplots(5, 6, figsize=(25, 25))  # Adjust grid size as needed\n",
    "anova_results = {}  # Dictionary to store ANOVA results for each feature\n",
    "\n",
    "# Collect all p-values to adjust them after the loop\n",
    "all_p_values = []\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    y_feature = feature  # The y-axis feature to plot\n",
    "\n",
    "    # Sorting 'ordered morph' for each plot\n",
    "    sns.violinplot(x='ordered morph', y=y_feature, data=new_ad.obs, ax=axes[row, col], inner='box', order=sorted(new_ad.obs['ordered morph'].unique()))\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    groups = [new_ad.obs[new_ad.obs['ordered morph'] == cluster][y_feature].dropna() for cluster in sorted(new_ad.obs['ordered morph'].unique())]\n",
    "    f_stat, p_value = stats.f_oneway(*groups)  # ANOVA calculation\n",
    "    \n",
    "    # Store the initial result and save the p-value for multiple testing correction\n",
    "    anova_results[feature] = {'F-statistic': f_stat, 'p-value': p_value}\n",
    "    all_p_values.append(p_value)\n",
    "\n",
    "    # Set basic title and labels before adding corrected p-value\n",
    "    axes[row, col].set_title(feature.replace('_', ' ').title())\n",
    "    axes[row, col].set_xlabel('Clusters')\n",
    "    axes[row, col].set_ylabel('Value')\n",
    "\n",
    "    if i == 24:  # Stop after the 25th feature\n",
    "        break\n",
    "\n",
    "# Apply multiple testing correction to all p-values\n",
    "_, corrected_p_values, _, _ = multipletests(all_p_values, method='fdr_bh')  # Benjamini-Hochberg (FDR) correction\n",
    "\n",
    "# Update anova_results with corrected p-values and update plot titles\n",
    "for i, feature in enumerate(features):\n",
    "    anova_results[feature]['corrected p-value'] = corrected_p_values[i]\n",
    "\n",
    "    # Update plot titles to include corrected p-value\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    if i < 25:  # To ensure we don't exceed subplot limits\n",
    "        axes[row, col].set_title(f\"{feature.replace('_', ' ').title()} (p={corrected_p_values[i]:.3f})\")\n",
    "    if i == 24:\n",
    "        break\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/morphology_by_cluster_sorted_clusters.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Optionally, display or save the ANOVA results\n",
    "anova_df = pd.DataFrame(anova_results).T  # Convert to DataFrame for easy viewing\n",
    "print(anova_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb2fbc-369b-4408-9d49-09837d48024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_bar(adata, group_col='sub_mic', cluster_col='morph_leiden',output_pdf=None):\n",
    "    \"\"\"\n",
    "    Create a stacked bar plot showing the relative percentage of each sub_mic group \n",
    "    corresponding to each morph_leiden cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - adata: AnnData object with obs columns for 'sub_mic' and 'morph_leiden'.\n",
    "    - group_col: Column name in obs representing the group (default: 'sub_mic').\n",
    "    - cluster_col: Column name in obs representing the clusters (default: 'morph_leiden').\n",
    "    \n",
    "    Returns:\n",
    "    - Displays a stacked bar plot.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from obs with relevant columns\n",
    "    df = adata.obs[[group_col, cluster_col]]\n",
    "    \n",
    "    # Calculate the counts of morph_leiden clusters within each sub_mic\n",
    "    count_df = pd.crosstab(df[group_col], df[cluster_col])\n",
    "    \n",
    "    # Convert counts to percentages\n",
    "    percentage_df = count_df.div(count_df.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Plot the stacked bar plot\n",
    "    ax = percentage_df.plot(kind='bar', stacked=True, figsize=(6, 6), colormap='tab20')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title('Relative Percentage of Each Sub_mic by Morph_leiden Cluster')\n",
    "    plt.xlabel('Sub_mic')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.legend(title='Morph_leiden Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    if output_pdf:\n",
    "        plt.savefig(output_pdf, format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_stacked_bar(new_ad, group_col='sub_mic', cluster_col='ordered_morph',output_pdf='figures/stacked_bar_morphology_in_transcripts.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30873f6e-2678-4524-aae1-846246d60f12",
   "metadata": {},
   "source": [
    "# DEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4359bb-9618-4745-a9fc-fdd1132c7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_deg(adata, groupby, group1, group2):\n",
    "    adata.obs['comparison'] = adata.obs[groupby].astype(str).apply(lambda x: group1 if x == group1 else (group2 if x == group2 else None))\n",
    "    adata_sub = adata[adata.obs['comparison'].notnull(), :].copy()\n",
    "    adata_sub.obs['comparison'] = adata_sub.obs['comparison'].astype('category')\n",
    "    adata_sub.obs['comparison'].cat.reorder_categories([group1, group2])\n",
    "    sc.tl.rank_genes_groups(adata_sub, 'comparison', reference=group1, method='wilcoxon',use_raw=False)\n",
    "    result = adata_sub.uns['rank_genes_groups']\n",
    "    groups = result['names'].dtype.names\n",
    "    deg_df = pd.DataFrame({\n",
    "        'names': result['names'][group2],\n",
    "        'logfoldchanges': result['logfoldchanges'][group2],\n",
    "        'pvals': result['pvals'][group2],\n",
    "        'pvals_adj': result['pvals_adj'][group2]\n",
    "    })\n",
    "    return deg_df\n",
    "\n",
    "def perform_deg_pop(adata, groupby, group1, group2, min_expr_fraction=0.3):\n",
    "    # Create comparison column\n",
    "    adata.obs['comparison'] = adata.obs[groupby].astype(str).apply(lambda x: group1 if x == group1 else (group2 if x == group2 else None))\n",
    "    adata_sub = adata[adata.obs['comparison'].notnull(), :].copy()\n",
    "    adata_sub.obs['comparison'] = adata_sub.obs['comparison'].astype('category')\n",
    "    adata_sub.obs['comparison'].cat.reorder_categories([group1, group2])\n",
    "    \n",
    "    # Calculate fraction of cells expressing each gene within group1 and group2\n",
    "    group1_cells = adata_sub[adata_sub.obs['comparison'] == group1]\n",
    "    group2_cells = adata_sub[adata_sub.obs['comparison'] == group2]\n",
    "    \n",
    "    expr_fraction_group1 = (group1_cells.X > 0).sum(axis=0) / group1_cells.shape[0]\n",
    "    expr_fraction_group2 = (group2_cells.X > 0).sum(axis=0) / group2_cells.shape[0]\n",
    "    \n",
    "    # Find genes expressed in at least 30% of cells in either group\n",
    "    valid_genes = (expr_fraction_group1 >= min_expr_fraction) | (expr_fraction_group2 >= min_expr_fraction)\n",
    "    \n",
    "    # Perform DEG analysis\n",
    "    sc.tl.rank_genes_groups(adata_sub, 'comparison', reference=group1, method='wilcoxon')\n",
    "    result = adata_sub.uns['rank_genes_groups']\n",
    "    groups = result['names'].dtype.names\n",
    "    \n",
    "    # Create DEG DataFrame\n",
    "    deg_df = pd.DataFrame({\n",
    "        'names': result['names'][group2],\n",
    "        'logfoldchanges': result['logfoldchanges'][group2],\n",
    "        'pvals': result['pvals'][group2],\n",
    "        'pvals_adj': result['pvals_adj'][group2]\n",
    "    })\n",
    "    \n",
    "    # Filter by valid genes\n",
    "    deg_df = deg_df[deg_df['names'].isin(adata.var_names[valid_genes])]\n",
    "    \n",
    "    return deg_df\n",
    "\n",
    "\n",
    "\n",
    "def perform_deg_stratified(adata, groupby, group1, group2, confounder):\n",
    "    # Initialize a DataFrame to store results\n",
    "    combined_deg_df = pd.DataFrame()\n",
    "\n",
    "    # Get unique values of the confounder (e.g., Age)\n",
    "    confounder_levels = adata.obs[confounder].unique()\n",
    "\n",
    "    for level in confounder_levels:\n",
    "        # Subset data to the current level of the confounder\n",
    "        adata_sub = adata[adata.obs[confounder] == level, :].copy()\n",
    "        \n",
    "        # Perform the differential expression analysis as before\n",
    "        adata_sub.obs['comparison'] = adata_sub.obs[groupby].astype(str).apply(\n",
    "            lambda x: group1 if x == group1 else (group2 if x == group2 else None))\n",
    "        adata_sub = adata_sub[adata_sub.obs['comparison'].notnull(), :].copy()\n",
    "        adata_sub.obs['comparison'] = adata_sub.obs['comparison'].astype('category')\n",
    "        adata_sub.obs['comparison'].cat.reorder_categories([group1, group2])\n",
    "\n",
    "        sc.tl.rank_genes_groups(adata_sub, 'comparison', reference=group1, method='wilcoxon')\n",
    "        result = adata_sub.uns['rank_genes_groups']\n",
    "\n",
    "        # Extract DEGs for the current level of the confounder\n",
    "        deg_df = pd.DataFrame({\n",
    "            'names': result['names'][group2],\n",
    "            'logfoldchanges': result['logfoldchanges'][group2],\n",
    "            'pvals': result['pvals'][group2],\n",
    "            'pvals_adj': result['pvals_adj'][group2],\n",
    "            'confounder_level': level\n",
    "        })\n",
    "\n",
    "        # Combine the results\n",
    "        combined_deg_df = pd.concat([combined_deg_df, deg_df], ignore_index=True)\n",
    "\n",
    "    return combined_deg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4f830-70c5-4bb7-adcf-c00c02a26214",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ad.X = new_ad.layers['total_counts'].copy()\n",
    "sc.pp.normalize_total(new_ad, target_sum=1e4)\n",
    "sc.pp.log1p(new_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd93256-6789-41ca-8f61-5f8cd0549599",
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology = perform_deg(new_ad, 'ordered_morph', '4', '0')\n",
    "transcriptome = perform_deg(new_ad, 'sub_mic', 'Homeostatic', 'DAM')\n",
    "\n",
    "morph = set(morphology[(morphology.pvals_adj < 0.05)]['names'])\n",
    "gene = set(transcriptome[(transcriptome.pvals_adj < 0.05)]['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bb233-27fa-44ee-88d4-462418b384e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "venn = venn2([morph, gene], ('Morphology', 'Genes'))\n",
    "plt.savefig('figures/venn_diagram.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbd4ad-1ae7-4f0d-8c78-54ffe189bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_names_1 = morph  # Example: set 1 (e.g., morphology-related genes)\n",
    "shared_names_2 = gene  # Example: set 2 (e.g., upregulated genes)\n",
    "\n",
    "# Convert to a list\n",
    "shared_genes_1 = list(shared_names_1)\n",
    "shared_genes_2 = list(shared_names_2)\n",
    "\n",
    "# Perform GO analysis using gseapy for biological processes, cellular components, and molecular functions\n",
    "gene_sets = ['GO_Biological_Process_2023']\n",
    "\n",
    "# Function to perform GO analysis and return the results\n",
    "def perform_go_analysis(genes, gene_sets, organism):\n",
    "    results = {}\n",
    "    for gene_set in gene_sets:\n",
    "        go_results = gp.enrichr(gene_list=genes,\n",
    "                                gene_sets=[gene_set],\n",
    "                                organism=organism,\n",
    "                                outdir=None)\n",
    "        results[gene_set] = go_results.results[['Term', 'Combined Score']].head(10)  # Get top 5 results\n",
    "    return results\n",
    "\n",
    "# GO analysis for both gene sets\n",
    "go_results_1 = perform_go_analysis(shared_genes_1, gene_sets, 'Mouse')\n",
    "go_results_2 = perform_go_analysis(shared_genes_2, gene_sets, 'Mouse')\n",
    "\n",
    "# Combine results into a single dataframe for easier plotting\n",
    "def perform_go_analysis(genes, gene_sets, organism):\n",
    "    results = {}\n",
    "    for gene_set in gene_sets:\n",
    "        go_results = gp.enrichr(gene_list=genes,\n",
    "                                gene_sets=[gene_set],\n",
    "                                organism=organism,\n",
    "                                outdir=None)\n",
    "        # Filter based on adjusted p-value < 0.01 and keep relevant columns\n",
    "        filtered_results = go_results.results[go_results.results['Adjusted P-value'] < 0.01]\n",
    "        results[gene_set] = filtered_results[['Term', 'Combined Score', 'Adjusted P-value']].head(10)  # Get top results\n",
    "    return results\n",
    "\n",
    "# GO analysis for both gene sets\n",
    "go_results_1 = perform_go_analysis(shared_genes_1, gene_sets, 'Mouse')\n",
    "go_results_2 = perform_go_analysis(shared_genes_2, gene_sets, 'Mouse')\n",
    "\n",
    "# Combine results into a single dataframe for easier plotting\n",
    "def merge_go_results(go_res_1, go_res_2, gene_set):\n",
    "    df_1 = go_res_1[gene_set].copy()\n",
    "    df_2 = go_res_2[gene_set].copy()\n",
    "    df_1['Set'] = 'Set 1'  # Label for first gene set\n",
    "    df_2['Set'] = 'Set 2'  # Label for second gene set\n",
    "    combined = pd.concat([df_1, df_2])\n",
    "    return combined\n",
    "\n",
    "# Merge the GO results for plotting\n",
    "combined_go_results = merge_go_results(go_results_1, go_results_2, 'GO_Biological_Process_2023')\n",
    "\n",
    "# Sort by the maximum Combined Score to ensure correct order\n",
    "combined_go_results['Max Combined Score'] = combined_go_results.groupby('Term')['Combined Score'].transform('max')\n",
    "combined_go_results = combined_go_results.sort_values(by='Max Combined Score', ascending=True).drop(columns='Max Combined Score')\n",
    "\n",
    "# Plotting the results\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Create bar plot colored by Set\n",
    "colors = {'Set 1': 'skyblue', 'Set 2': 'salmon'}\n",
    "for label, df_subset in combined_go_results.groupby('Set'):\n",
    "    ax.barh(df_subset['Term'], df_subset['Combined Score'], label=label, color=colors[label])\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Combined Score')\n",
    "ax.set_title('Top GO Terms for Two Gene Sets (Biological Process)')\n",
    "ax.invert_yaxis()  # Display the highest values on top\n",
    "ax.legend()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/morphology_genes_GO_comparison_filtered.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece34cd4-b506-427f-a63c-0abdfc44a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ad.X = new_ad.layers['total_counts'].copy()\n",
    "sc.pp.normalize_total(new_ad,target_sum=1e4)\n",
    "sc.pp.log1p(new_ad)\n",
    "sc.tl.score_genes(new_ad,gene_list=['Slc1a2','Gria2','Dlgap2','Dlg2','Dagla'],score_name='glut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b46ab-d1b2-433c-a514-cf428ad6687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAM_cells = new_ad[(new_ad.obs.sub_mic == 'DAM') & (new_ad.obs.ordered_morph.isin(['0','4']))]\n",
    "homeostatic_cells = new_ad[(new_ad.obs.sub_mic == 'Homeostatic') & (new_ad.obs.ordered_morph.isin(['0','4']))]\n",
    "\n",
    "DAM_morph = perform_deg(DAM_cells, 'ordered_morph', '4', '0')\n",
    "homeo_morph = perform_deg(homeostatic_cells, 'ordered_morph', '4', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f7631-c5d3-4897-bbb2-470cb0076698",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(homeostatic_cells,keys='glut',groupby='ordered_morph',use_raw=False,size=3,save='active_glut.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
