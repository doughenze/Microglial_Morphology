{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91e8fa9-dd7c-494b-8c2e-9de16d20d2d1",
   "metadata": {},
   "source": [
    "The code to analyze the permutations is adapted from: https://github.com/ZhuangLab/whole_mouse_brain_MERFISH_atlas_scripts_2023/blob/main/scripts/cell_cell_contacts/get_significant_contacts_30um.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa878ac-995c-4d22-b032-e27a60785b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import string\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "import Mapping\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import gseapy as gp\n",
    "import networkx as nx\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "from skimage.morphology import disk, opening, closing\n",
    "from scipy.ndimage import binary_fill_holes, label, distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries, watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from skimage.segmentation import watershed\n",
    "import scipy.stats\n",
    "import statsmodels.stats.multitest\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import networkx as nx\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dafb1a6-36ec-46fa-b478-3347de3722b7",
   "metadata": {},
   "source": [
    "# CLQ Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b89be2-3552-4e72-be3a-b4f8dad661b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clq_array(base_path, batch_list, morphology_list, output_p,compartment='soma'):\n",
    "    final_clq = []\n",
    "    for morph in morphology_list:\n",
    "        for batch in batch_list\n",
    "            transcripts = find_filtered_transcripts(base_path+batch+'/')\n",
    "            genes = np.unique(transcripts.gene.unique().tolist())        \n",
    "            soma_clq.append(np.load(f'{output_p}{batch}/morph_{morph}/{compartment}_clq_scores.npy'))\n",
    "    final_array = np.concatenate(final_clq, axis=0)\n",
    "    return final_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debeae7-d4ba-457c-8e25-5a70c5581f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables\n",
    "output_path = 'permutation_coloc/'\n",
    "morphologies = ['0','1','2','3','4']\n",
    "batches =['3-mo-male-1',\n",
    "          '3-mo-male-2',\n",
    "          '3-mo-male-3-rev2',\n",
    "          '3-mo-female-1-rev2',\n",
    "          '3-mo-female-2',\n",
    "          '3-mo-female-3',\n",
    "          '24-mo-male-1',\n",
    "          '24-mo-male-2',\n",
    "          '24-mo-male-4-rev2',\n",
    "          '24-mo-female-1',\n",
    "          '24-mo-female-3',\n",
    "          '24-mo-female-5']\n",
    "# adjust this to your base path\n",
    "base_data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1173c76-5cfb-4874-9845-89e92e1ea1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_array_soma = clq_array(base_data_path, batches, morphologies, output_path,compartment='soma')\n",
    "final_array_branches = clq_array(base_data_path, batches, morphologies, output_path,compartment='branches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956460fb-0325-4150-987f-2a3a68989d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the soma cluster map and record the order of genes\n",
    "average_array_soma = np.mean(final_array_soma, axis=0)\n",
    "df_soma = pd.DataFrame(average_array_soma, index=genes, columns=genes)\n",
    "\n",
    "g = sns.clustermap(\n",
    "    df_soma,\n",
    "    cmap='Reds',\n",
    "    figsize=(10, 10),\n",
    "    method='average',\n",
    "    metric='euclidean',\n",
    "    vmax = 2.0,\n",
    "    cbar_kws={'label': 'Average CLQ Score'}\n",
    ")\n",
    "gene_order = g.dendrogram_row.reordered_ind  # Save the ordered row indices\n",
    "ordered_genes_list = df_soma.index[gene_order].tolist()  # Get the ordered gene names\n",
    "plt.savefig('coloc_figs/soma_clq.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac24061-0fd9-405b-bda6-627c6eb4bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the branches clustermap to match the gene order of the soma clustermap\n",
    "average_array_branches = np.mean(final_array_branches, axis=0)\n",
    "df_branches = pd.DataFrame(average_array_branches, index=genes, columns=genes)\n",
    "\n",
    "df_branches_ordered = df_branches.loc[ordered_genes_list, ordered_genes_list]\n",
    "\n",
    "# Plot the clustermap for df2 with the saved ordering\n",
    "sns.clustermap(\n",
    "    df_branches_ordered,\n",
    "    cmap='Reds',         # Change the colormap if desired\n",
    "    figsize=(10, 10),\n",
    "    row_cluster=False,       # Disable row clustering\n",
    "    col_cluster=False,\n",
    "    vmax=2.0,\n",
    "    cbar_kws={'label': 'Second Dataset CLQ Score'}\n",
    ")\n",
    "\n",
    "plt.title('Clustermap with Preserved Ordering', fontsize=16)\n",
    "plt.savefig('coloc_figs/branches_clq.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b04441-80b8-4fad-8151-82086b575d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustermap_subset(graph,df,df2,n_genes,save_pdf=None)\n",
    "    '''\n",
    "    Plotting the top right square of n_genes.\n",
    "    \n",
    "    graph = clustermap object\n",
    "    df = dataframe with genes in the correct order\n",
    "    df2 = dataframe with the values we are graphing\n",
    "    n_genes = size of square at the top left we want to graph\n",
    "    \n",
    "    '''\n",
    "    gene_order = graph.dendrogram_row.reordered_ind  # Row order from the dendrogram\n",
    "    ordered_genes = df.index[gene_order]  # Ordered gene names\n",
    "    \n",
    "    subset_genes = ordered_genes[:n_genes]\n",
    "\n",
    "# Subset the DataFrame for the cluster of interest\n",
    "    df_subset = df2.loc[subset_genes, subset_genes]\n",
    "\n",
    "    # Visualize the subset as a clustermap or heatmap\n",
    "    sns.heatmap(\n",
    "        df_subset,\n",
    "        cmap='Reds',\n",
    "        vmax=2.0,\n",
    "        vmin=0,\n",
    "        cbar_kws={'label': 'Average CLQ Score'}\n",
    "    )\n",
    "\n",
    "    plt.title('Subset of Genes in Bottom-Right Cluster', fontsize=16)\n",
    "    if save_pdf:\n",
    "        plt.savefig(save_pdf, format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecd9a2-db87-4ab4-93df-79263f2bb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot soma clq subset\n",
    "plot_clustermap_subset(g,df_soma, df_soma,14,save_pdf='coloc_figs/soma_clq_subset.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990c3a0-61ef-4450-a670-3f4f17a856be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot branches clq subset\n",
    "plot_clustermap_subset(g,df_soma, df_branches_ordered,14,save_pdf='coloc_figs/branches_clq_subset.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dca7da-2468-4f08-868a-040cb1e904a7",
   "metadata": {},
   "source": [
    "# Colocalization Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a098ce-b4a8-4735-9589-25d937658e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero_pairs(contact_mtx):\n",
    "    n_0 = 0\n",
    "    for i in range(contact_mtx.shape[0]):\n",
    "        for j in range(i, contact_mtx.shape[0]):\n",
    "            if contact_mtx[i, j] == 0:\n",
    "                n_0 += 1\n",
    "    return n_0\n",
    "\n",
    "def adjust_p_value_matrix_by_BH(p_val_mtx):\n",
    "    '''Adjust the p-values in a matrix by the Benjamini/Hochberg method.\n",
    "    The matrix should be symmetric.\n",
    "    '''\n",
    "    p_val_sequential = []\n",
    "    N = p_val_mtx.shape[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            p_val_sequential.append(p_val_mtx[i, j])\n",
    "\n",
    "    p_val_sequential_bh = statsmodels.stats.multitest.multipletests(p_val_sequential, method='fdr_bh')[1]\n",
    "    \n",
    "    adjusted_p_val_mtx = np.zeros((N, N))\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            adjusted_p_val_mtx[i, j] = p_val_sequential_bh[counter]\n",
    "            adjusted_p_val_mtx[j, i] = p_val_sequential_bh[counter]\n",
    "            counter += 1\n",
    "            \n",
    "    return adjusted_p_val_mtx\n",
    "\n",
    "def get_data_frame_from_metrices(cell_types, mtx_dict):\n",
    "    N = len(cell_types)\n",
    "    \n",
    "    serials_dict = {'cell_type1':[], 'cell_type2':[]}\n",
    "    for k in mtx_dict.keys():\n",
    "        serials_dict[k] = []\n",
    "        \n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            serials_dict['cell_type1'].append(cell_types[i])\n",
    "            serials_dict['cell_type2'].append(cell_types[j])\n",
    "            for k in mtx_dict.keys():\n",
    "                serials_dict[k].append(mtx_dict[k][i, j])\n",
    "                \n",
    "    return pd.DataFrame(serials_dict)\n",
    "    \n",
    "\n",
    "def sort_cell_type_contact_p_values(p_val_mtx, cell_types):\n",
    "    '''Return a list of (cell_type1, cell_type2, p_value) sorted by p_values.'''\n",
    "    p_val_list = []\n",
    "    N = p_val_mtx.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            p_val_list.append((cell_types[i], cell_types[j], p_val_mtx[i, j]))\n",
    "    return sorted(p_val_list, key=lambda x:x[2])\n",
    "\n",
    "import scipy.cluster\n",
    "#from scattermap import scattermap\n",
    "\n",
    "def get_optimal_order_of_mtx(X):\n",
    "    Z = scipy.cluster.hierarchy.ward(X)\n",
    "    return scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(Z, X))\n",
    "\n",
    "def get_ordered_tick_labels(tick_labels):\n",
    "    tick_labels_with_class = [s.split(' ')[-1] + ' ' + s for s in tick_labels]\n",
    "    return np.argsort(tick_labels_with_class)\n",
    "\n",
    "def filter_pval_mtx(pval_mtx, tick_labels, allowed_pairs):\n",
    "    pval_mtx_filtered = pval_mtx.copy()\n",
    "    \n",
    "    for i in range(pval_mtx.shape[0]):\n",
    "        ct1 = tick_labels[i]\n",
    "        for j in range(pval_mtx.shape[1]):\n",
    "            ct2 = tick_labels[j]\n",
    "            \n",
    "            if ((ct1, ct2) in allowed_pairs) or ((ct2, ct1) in allowed_pairs):\n",
    "                continue\n",
    "            else:\n",
    "                pval_mtx_filtered[i, j] = 1\n",
    "            \n",
    "    return pval_mtx_filtered\n",
    "\n",
    "def make_dotplot(pval_mtx, fold_change_mtx, tick_labels, title='', allowed_pairs=None):\n",
    "\n",
    "    #optimal_order = get_optimal_order_of_mtx(pval_mtx)\n",
    "    optimal_order = get_ordered_tick_labels(tick_labels)\n",
    "    \n",
    "    pval_mtx = pval_mtx[optimal_order][:, optimal_order]\n",
    "    fold_change_mtx = fold_change_mtx[optimal_order][:, optimal_order]\n",
    "    tick_labels = tick_labels[optimal_order]\n",
    "    \n",
    "    \n",
    "def find_filtered_transcripts(experiment_path):\n",
    "    region_types = ['region_0', 'region_1']\n",
    "    for region in region_types:\n",
    "        file_path = f'{experiment_path}baysor/detected_transcripts.csv'\n",
    "        if os.path.exists(file_path):\n",
    "            return pd.read_csv(file_path,index_col=0)\n",
    "    return None\n",
    "\n",
    "def permutation_analysis(base_path, batch_list, morphology_list, output_p,compartment='soma'):\n",
    "    full_df = []\n",
    "    # so I want to iterate through each geometry class\n",
    "    for morph in morphology_list:\n",
    "        # then through every batch\n",
    "        for batch in batch_list:\n",
    "            # load the gene names\n",
    "            transcripts = find_filtered_transcripts(base_path+batch+'/')\n",
    "            genes = np.unique(transcripts.gene.unique().tolist())\n",
    "    \n",
    "            gene_coloc_counts = np.load(f'{output_p}{batch}/morph_{morph}/{compartment}_no_permutation.npy')\n",
    "\n",
    "            local_null_means = np.load(f'{output_p}{batch}/morph_{morph}/{compartment}_full_permutation_mean.npy')\n",
    "            local_null_stds = np.load(f'{output_p}{batch}/morph_{morph}/{compartment}_full_permutation_std.npy')\n",
    "\n",
    "            # Require all stds to be larger or equal to the minimal observable std value\n",
    "            local_null_stds = np.maximum(local_null_stds, np.sqrt(1 / 1000))\n",
    "    \n",
    "            local_z_scores = (gene_coloc_counts - local_null_means) / local_null_stds\n",
    "            local_p_values = scipy.stats.norm.sf(local_z_scores)\n",
    "            adjusted_local_p_values = adjust_p_value_matrix_by_BH(local_p_values)\n",
    "    \n",
    "            fold_changes = gene_coloc_counts / (local_null_means + 1e-4)\n",
    "        \n",
    "            # Gather all results into a data frame\n",
    "            contact_result_df = get_data_frame_from_metrices(genes, \n",
    "                                             {'pval-adjusted': adjusted_local_p_values,\n",
    "                                              'pval': local_p_values,\n",
    "                                              'z_score': local_z_scores,\n",
    "                                              'contact_count': gene_coloc_counts,\n",
    "                                              'permutation_mean': local_null_means,\n",
    "                                              'permutation_std': local_null_stds,\n",
    "                                            }).sort_values('z_score', ascending=False)\n",
    "\n",
    "            \n",
    "            contact_result_df.to_csv(f'{output_p}{batch}/morph_{morph}/{compartment}_close_contacts.csv')\n",
    "    \n",
    "            full_df.append(contact_result_df)\n",
    "        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d4b5e-4aa3-470b-b800-1f2200a0d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name all of the necessary variables\n",
    "\n",
    "output_path = 'permutation_coloc/'\n",
    "morphologies = ['0','1','2','3','4']\n",
    "batches =['3-mo-male-1',\n",
    "          '3-mo-male-2',\n",
    "          '3-mo-male-3-rev2',\n",
    "          '3-mo-female-1-rev2',\n",
    "          '3-mo-female-2',\n",
    "          '3-mo-female-3',\n",
    "          '24-mo-male-1',\n",
    "          '24-mo-male-2',\n",
    "          '24-mo-male-4-rev2',\n",
    "          '24-mo-female-1',\n",
    "          '24-mo-female-3',\n",
    "          '24-mo-female-5']\n",
    "\n",
    "# replace with where the data is kept\n",
    "base_data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ce7eb-44c7-429b-a6ab-f1db23a77720",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_df = permutation_analysis(base_data_path, batches, morphologies, output_path,compartment='soma')\n",
    "branches_df = permutation_analysis(base_data_path, batches, morphologies, output_path,compartment='branches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96ac6f-d91b-417d-82a3-0947ede60896",
   "metadata": {},
   "source": [
    "# Trimming the dataframes and looking at specific morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bac60a-6aa6-4274-8217-9db676743e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_disconnected_pairs(df, node1_col, node2_col):\n",
    "    \"\"\"\n",
    "    Remove disconnected components with only two nodes from the graph created by the DataFrame.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing at least two columns representing edges in a graph.\n",
    "        node1_col (str): Name of the first column representing nodes (e.g., 'cell_type1').\n",
    "        node2_col (str): Name of the second column representing nodes (e.g., 'cell_type2').\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame containing only edges from valid components.\n",
    "    \"\"\"\n",
    "    # Create a graph from the DataFrame\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(zip(df[node1_col], df[node2_col]))\n",
    "\n",
    "    # Identify connected components\n",
    "    components = list(nx.connected_components(G))\n",
    "\n",
    "    # Keep only components with more than two nodes\n",
    "    valid_components = [comp for comp in components if len(comp) > 2]\n",
    "\n",
    "    # Flatten the valid components into a set of nodes\n",
    "    valid_nodes = set(node for comp in valid_components for node in comp)\n",
    "\n",
    "    # Filter the DataFrame to retain only rows where both nodes are in valid components\n",
    "    filtered_df = df[\n",
    "        (df[node1_col].isin(valid_nodes)) &\n",
    "        (df[node2_col].isin(valid_nodes))\n",
    "    ]\n",
    "    return filtered_df\n",
    "\n",
    "def extract_coloc_tables(morphologies, batches, contact_thresh=4, pval_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Extract and filter colocalization tables for soma and branches, \n",
    "    including filtering out disconnected graph components with only two nodes.\n",
    "\n",
    "    Args:\n",
    "        morphologies (list): List of morphology types.\n",
    "        batches (list): List of batch identifiers.\n",
    "        contact_thresh (int): Minimum contact count threshold for filtering.\n",
    "        pval_thresh (float): Maximum adjusted p-value threshold for filtering.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Filtered soma and branches DataFrames.\n",
    "    \"\"\"\n",
    "    soma_df = []\n",
    "    branches_df = []\n",
    "\n",
    "    # Iterate over morphologies and batches to load data\n",
    "    for morph in morphologies:\n",
    "        for batch in batches:\n",
    "            soma_df.append(pd.read_csv(f'{output_path}{batch}/morph_{morph}/soma_close_contacts.csv', index_col=0))\n",
    "            branches_df.append(pd.read_csv(f'{output_path}{batch}/morph_{morph}/branches_close_contacts.csv', index_col=0))\n",
    "\n",
    "    # Combine all data\n",
    "    soma_full = pd.concat(soma_df)\n",
    "    branches_full = pd.concat(branches_df)\n",
    "\n",
    "    # Apply initial filtering based on thresholds\n",
    "    soma_full = soma_full[\n",
    "        (soma_full.contact_count > contact_thresh) &\n",
    "        (soma_full['pval-adjusted'] < pval_thresh) &\n",
    "        (soma_full.cell_type1 != soma_full.cell_type2)\n",
    "    ]\n",
    "\n",
    "    branches_full = branches_full[\n",
    "        (branches_full.contact_count > contact_thresh) &\n",
    "        (branches_full['pval-adjusted'] < pval_thresh) &\n",
    "        (branches_full.cell_type1 != branches_full.cell_type2)\n",
    "    ]\n",
    "\n",
    "    # Group by cell_type1 and cell_type2, averaging numerical values\n",
    "    soma_full = soma_full.groupby(['cell_type1', 'cell_type2']).mean().reset_index()\n",
    "    branches_full = branches_full.groupby(['cell_type1', 'cell_type2']).mean().reset_index()\n",
    "\n",
    "    # Apply graph-based filtering to remove disconnected pairs\n",
    "    soma_full = filter_disconnected_pairs(soma_full, 'cell_type1', 'cell_type2')\n",
    "    branches_full = filter_disconnected_pairs(branches_full, 'cell_type1', 'cell_type2')\n",
    "\n",
    "    return soma_full, branches_full\n",
    "\n",
    "def save_dataframes_to_excel(dataframes, sheet_names, output_path):\n",
    "    \"\"\"\n",
    "    Save multiple DataFrames to a single Excel file, with each DataFrame on a separate sheet.\n",
    "\n",
    "    Args:\n",
    "        dataframes (list): List of pandas DataFrames to save.\n",
    "        sheet_names (list): List of sheet names corresponding to each DataFrame.\n",
    "        output_path (str): Path to save the Excel file (e.g., 'output.xlsx').\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        for df, sheet_name in zip(dataframes, sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    print(f\"DataFrames saved to {output_path}\")\n",
    "\n",
    "def plot_contact_network_with_clusters_spectral(df, title, threshold=0.05, n_clusters=3,save_path=None):\n",
    "    \"\"\"\n",
    "    Plot a gene-gene contact network and identify clusters using Spectral Clustering.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with gene-gene interaction data.\n",
    "        title (str): Title of the plot (e.g., 'Young' or 'Old').\n",
    "        threshold (float): p-value threshold to filter significant interactions.\n",
    "        n_clusters (int): Number of clusters to identify.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are cluster IDs and values are lists of nodes in each cluster.\n",
    "    \"\"\"\n",
    "    # Filter data based on p-value threshold\n",
    "    df_filtered = df[df['pval-adjusted'] < threshold]\n",
    "\n",
    "    # Create a network graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with weights based on z_score\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        G.add_edge(row['cell_type1'], row['cell_type2'], weight=row['z_score'])\n",
    "    \n",
    "    # Convert graph to adjacency matrix\n",
    "    adjacency_matrix = nx.to_numpy_array(G)\n",
    "\n",
    "    # Perform Spectral Clustering\n",
    "    clustering = SpectralClustering(\n",
    "        n_clusters=n_clusters, \n",
    "        affinity='precomputed', \n",
    "        random_state=42\n",
    "    ).fit(adjacency_matrix)\n",
    "\n",
    "    # Assign cluster labels\n",
    "    node_list = list(G.nodes())\n",
    "    cluster_labels = clustering.labels_  # Cluster labels for each node\n",
    "    \n",
    "    # Group nodes by cluster\n",
    "    clusters = {}\n",
    "    for node, cluster_id in zip(node_list, cluster_labels):\n",
    "        clusters.setdefault(cluster_id, []).append(node)\n",
    "    \n",
    "    # Draw the network with cluster-based coloring\n",
    "    pos = nx.spring_layout(G, seed=42)  # Layout for consistent visualization\n",
    "    cluster_colors = cluster_labels  # Colors based on cluster IDs\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, node_size=400, node_color=cluster_colors, cmap=plt.cm.Set3, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=1.0, edge_color='gray', alpha=0.5)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')\n",
    "    \n",
    "    # Add a legend for the clusters\n",
    "    cluster_ids = list(set(cluster_labels))\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label=f'Cluster {cluster_id}',\n",
    "               markerfacecolor=plt.cm.Set3(cluster_id / max(cluster_ids)), markersize=10)\n",
    "        for cluster_id in cluster_ids\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, title='Clusters', loc='upper right')\n",
    "    \n",
    "    # Add title\n",
    "    plt.title(title, fontsize=16)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(f'coloc_figs/{save_path}', format='pdf')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def perform_go_enrichment(clusters_dict, organism='Mouse'):\n",
    "    \"\"\"\n",
    "    Perform GO enrichment analysis for each cluster and save results.\n",
    "\n",
    "    Args:\n",
    "        clusters_dict (dict): Dictionary where keys are cluster IDs and values are lists of genes.\n",
    "        output_dir (str): Directory to save GO enrichment results.\n",
    "        organism (str): Organism for enrichment analysis ('Human' or 'Mouse').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are cluster IDs and values are DataFrames of enrichment results.\n",
    "    \"\"\"\n",
    "    go_results = {}\n",
    "    \n",
    "    for cluster_id, genes in clusters_dict.items():\n",
    "        # Perform GO enrichment analysis\n",
    "        enrichment_results = gp.enrichr(\n",
    "            gene_list=genes,  # List of genes in the cluster\n",
    "            gene_sets='GO_Biological_Process_2023',  # Gene Ontology Biological Process\n",
    "            organism=organism\n",
    "        )\n",
    "        \n",
    "        # Store results in dictionary\n",
    "        go_results[cluster_id] = enrichment_results.results\n",
    "    \n",
    "    return go_results\n",
    "\n",
    "def plot_go_enrichment(go_results, top_n=5, save_path=None, global_max_score=None, figure_width=10):\n",
    "    \"\"\"\n",
    "    Plot a horizontal bar graph of the top GO terms for each cluster, ensuring consistent graph sizes.\n",
    "    \n",
    "    Args:\n",
    "        go_results (dict): Dictionary where keys are cluster IDs and values are DataFrames of GO enrichment results.\n",
    "        top_n (int): Number of top GO terms to display per cluster.\n",
    "        save_path (str): Path to save the figure as a PDF (optional).\n",
    "        global_max_score (float): Global maximum score for x-axis synchronization (optional).\n",
    "        figure_width (float): Fixed width of the graph area (excluding labels).\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for cluster_id, df in go_results.items():\n",
    "        # Select top N GO terms based on adjusted p-value\n",
    "        top_terms = df.sort_values('Adjusted P-value').head(top_n)\n",
    "        for _, row in top_terms.iterrows():\n",
    "            plot_data.append({\n",
    "                'Cluster': cluster_id,\n",
    "                'GO Term': row['Term'],\n",
    "                '-log10(P-value)': -np.log10(row['Adjusted P-value']),\n",
    "                'Combined Score': row['Combined Score']\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Determine the x-axis limit\n",
    "    max_score = global_max_score or plot_df['Combined Score'].max()\n",
    "\n",
    "    # Estimate space needed for y-axis labels\n",
    "    max_label_length = plot_df['GO Term'].str.len().max()\n",
    "    label_width = max_label_length * 0.1  # Estimate label width in inches (adjust scaling factor as needed)\n",
    "    total_width = figure_width + label_width\n",
    "\n",
    "    # Plot horizontal bar graph\n",
    "    plt.figure(figsize=(total_width, len(plot_df) * 0.4))\n",
    "    sns.barplot(\n",
    "        data=plot_df,\n",
    "        y='GO Term',\n",
    "        x='Combined Score',\n",
    "        hue='Cluster',\n",
    "        dodge=False,  # Avoid overlapping bars\n",
    "        palette='Set2'\n",
    "    )\n",
    "    plt.xlabel('Combined Score', fontsize=12)\n",
    "    plt.ylabel('GO Term', fontsize=12)\n",
    "    plt.xlim([0, max_score])  # Use the global max score for consistent x-axes\n",
    "    plt.title('GO Enrichment Analysis by Cluster', fontsize=14)\n",
    "    plt.legend(title='Cluster', loc='best')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(f'coloc_figs/{save_path}', format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ccec1-9afd-4747-bd35-fcfa00c9e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batches (split by age) and most complex morphology\n",
    "morphologies = ['4']\n",
    "\n",
    "batches_3 =['3-mo-male-1',\n",
    "          '3-mo-male-2',\n",
    "          '3-mo-male-3-rev2',\n",
    "          '3-mo-female-1-rev2',\n",
    "          '3-mo-female-2',\n",
    "          '3-mo-female-3']\n",
    "\n",
    "batches_24 =['24-mo-male-1',\n",
    "          '24-mo-male-2',\n",
    "          '24-mo-male-4-rev2',\n",
    "          '24-mo-female-1',\n",
    "          '24-mo-female-3',\n",
    "          '24-mo-female-5']\n",
    "\n",
    "young_4_soma, young_4_branches = extract_coloc_tables(morphologies, batches_3)\n",
    "old_4_soma, old_4_branches = extract_coloc_tables(morphologies, batches_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d40d67-b600-4744-88f9-e3fa3f5dddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [young_4_soma, young_4_branches, old_4_soma, old_4_branches]\n",
    "sheet_names = ['Young_Soma', 'Young_Processes', 'Old_Soma', 'Old_Processes']\n",
    "\n",
    "output_file = 'coloc_figs/gene_colocalization_networks.xlsx'\n",
    "save_dataframes_to_excel(dataframes, sheet_names, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5ae55-fdf0-4aa3-b8ff-a612d3c35006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graphs of the colocalization networks, clusters set to 3 by default, can manually tune\n",
    "young_soma_gene_clusters = plot_contact_network_with_clusters_spectral(young_4_soma, '3 month soma', threshold=0.05,save_path='3_month_soma.pdf')\n",
    "young_branches_gene_clusters = plot_contact_network_with_clusters_spectral(young_4_branches, '3 month branches', threshold=0.05,n_clusters=2,save_path='3_month_branches.pdf')\n",
    "old_soma_gene_clusters = plot_contact_network_with_clusters_spectral(old_4_soma, '24 month soma', threshold=0.05,n_clusters=1,save_path='24_month_soma.pdf')\n",
    "old_branches_gene_clusters = plot_contact_network_with_clusters_spectral(old_4_branches, '24 month branches', threshold=0.05,n_clusters=2,save_path='24_month_branches.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1515d40-6239-4bc5-bc7d-9679b0d83e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 month soma gene ontology\n",
    "results = perform_go_enrichment(young_soma_gene_clusters)\n",
    "plot_go_enrichment(results, top_n=5,save_path='3_month_soma_GO.pdf',global_max_score=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ce375-23e6-49b5-845c-bf2dc847d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 month soma gene ontology\n",
    "results = perform_go_enrichment(old_soma_gene_clusters)\n",
    "plot_go_enrichment(results, top_n=5,save_path='24_month_soma_GO.pdf',global_max_score=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7801591-af6a-491f-adf9-c0df79ea2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 month branches gene ontology\n",
    "results = perform_go_enrichment(young_branches_gene_clusters)\n",
    "plot_go_enrichment(results, top_n=5,save_path='3_month_branches_GO.pdf',global_max_score=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49790c3f-cb26-41b7-a47e-5410bddc4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 month branches gene ontology\n",
    "results = perform_go_enrichment(old_branches_gene_clusters)\n",
    "plot_go_enrichment(results, top_n=5,save_path='24_month_branches_GO.pdf',global_max_score=20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
